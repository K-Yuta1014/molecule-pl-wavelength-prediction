{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f56bc6e",
   "metadata": {},
   "source": [
    "# 新規材料の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcce2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/xgboost/compat.py:105: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', font_scale=1.2)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e46c7",
   "metadata": {},
   "source": [
    "## データ読み込み＆前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec76cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ形状: (233, 3) (233, 217) (233, 2048) (233, 1158) (233, 1826)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み、学習データ＋未知のデータ\n",
    "data = pd.read_csv('material_data.csv', index_col=0)\n",
    "des_rdkit = pd.read_csv('descriptor_rdkit.csv', index_col=0)\n",
    "fingerprint_df = pd.read_csv('morganFP.csv', index_col=0)\n",
    "des_mordred_2d = pd.read_csv('descriptor_mordred_2d.csv', index_col=0)\n",
    "des_mordred_3d = pd.read_csv('descriptor_mordred_3d.csv', index_col=0)\n",
    "\n",
    "print(\"データ形状:\", data.shape, des_rdkit.shape, fingerprint_df.shape, des_mordred_2d.shape, des_mordred_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f1edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前処理後のデータ形状: (228, 152) (5, 151)\n"
     ]
    }
   ],
   "source": [
    "# 結合\n",
    "dataset = pd.concat([data.reset_index(), des_rdkit.reset_index(drop=True)], axis=1)\n",
    "dataset.index = dataset['Material']\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "\n",
    "# TypeとSMILESも消す\n",
    "dataset = dataset.drop(['SMILES', 'Type'], axis=1)\n",
    "\n",
    "# 学習用と予測用に分ける\n",
    "dataset_train = dataset.dropna(subset='PL')\n",
    "dataset_test = dataset[dataset['PL'].isnull()]\n",
    "\n",
    "# 予測データのPLは空なので消す\n",
    "dataset_test = dataset_test.drop('PL', axis=1)\n",
    "\n",
    "# infをNaNに置き換え\n",
    "dataset_train = dataset_train.replace(np.inf, np.nan).fillna(np.nan)\n",
    "dataset_train = dataset_train.drop(dataset_train.columns[dataset_train.isnull().any()], axis=1)\n",
    "\n",
    "dataset_test = dataset_test.replace(np.inf, np.nan).fillna(np.nan)\n",
    "dataset_test = dataset_test.drop(dataset_test.columns[dataset_test.isnull().any()], axis=1)\n",
    "\n",
    "# 学習データのstdが0の列を特定\n",
    "zero_std_cols = dataset_train.columns[dataset_train.std() == 0]\n",
    "\n",
    "# 学習・未知データから同じ列を削除\n",
    "dataset_train = dataset_train.drop(columns=zero_std_cols)\n",
    "dataset_test = dataset_test.drop(columns=zero_std_cols, errors='ignore')\n",
    "\n",
    "print(\"前処理後のデータ形状:\", dataset_train.shape, dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199f65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な特徴量共通セット\n",
    "X_train_all = dataset_train.drop(columns='PL')\n",
    "y_train_all = dataset_train['PL']\n",
    "X_test = dataset_test  # PLなし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35092a",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e79ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cpu\n"
     ]
    }
   ],
   "source": [
    "# CPU専用設定\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"使用デバイス: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b46dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット定義\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 学習loop\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 評価（修正版）\n",
    "def evaluate(model, dataloader, device, y_scaler):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.cpu().numpy()\n",
    "            pred = model(X_batch).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            trues.append(y_batch)\n",
    "\n",
    "    y_pred_std = np.vstack(preds)\n",
    "    y_true_std = np.vstack(trues)\n",
    "\n",
    "    # 逆標準化\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_std).flatten()\n",
    "    y_true = y_scaler.inverse_transform(y_true_std).flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af209451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna設定（修正版）\n",
    "def define_model(trial, input_dim):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)  # 範囲を狭める\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 256)  # 範囲を狭める\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"])\n",
    "\n",
    "    layers = []\n",
    "    current_dim = input_dim\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU() if activation == \"relu\" else nn.LeakyReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        current_dim = hidden_dim\n",
    "    \n",
    "    layers.append(nn.Linear(hidden_dim, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータ提案\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    epochs = trial.suggest_int(\"epochs\", 30, 100)  # エポック数も最適化\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    val_losses = []\n",
    "\n",
    "    # 分割前に標準化\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X = X_scaler.fit_transform(X_train_all)\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y = y_scaler.fit_transform(y_train_all.values.reshape(-1, 1))\n",
    "\n",
    "    for train_idx, val_idx in kf.split(autoscaled_X):\n",
    "        # スライス\n",
    "        X_train, X_val = autoscaled_X[train_idx], autoscaled_X[val_idx]\n",
    "        y_train, y_val = autoscaled_y[train_idx], autoscaled_y[val_idx]\n",
    "\n",
    "        # Dataset, DataLoader\n",
    "        train_ds = RegressionDataset(X_train, y_train)\n",
    "        val_ds = RegressionDataset(X_val, y_val)\n",
    "\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # モデル定義\n",
    "        model = define_model(trial, X_train.shape[1]).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # 学習ループ（Early Stopping追加）\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 10\n",
    "        no_improve = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_epoch(model, train_dl, optimizer, criterion, device)\n",
    "            val_loss = evaluate(model, val_dl, device, y_scaler)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                \n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "        val_losses.append(best_val_loss)\n",
    "\n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 21:03:41,567] A new study created in memory with name: no-name-9da7f0b6-d4f1-42dc-a2f6-9d5c85bff04f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna最適化開始...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 21:03:54,431] Trial 0 finished with value: 47.105861695292774 and parameters: {'batch_size': 32, 'lr': 0.008481733450322751, 'optimizer': 'SGD', 'epochs': 92, 'n_layers': 2, 'hidden_dim': 164, 'dropout_rate': 0.4433784950601598, 'activation': 'relu'}. Best is trial 0 with value: 47.105861695292774.\n",
      "[I 2025-07-03 21:03:59,238] Trial 1 finished with value: 42.43999237766509 and parameters: {'batch_size': 64, 'lr': 0.000271920742701073, 'optimizer': 'Adam', 'epochs': 75, 'n_layers': 2, 'hidden_dim': 123, 'dropout_rate': 0.3318458204753981, 'activation': 'leaky_relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:04:13,764] Trial 2 finished with value: 80.64582844813569 and parameters: {'batch_size': 16, 'lr': 0.00041933820615399215, 'optimizer': 'SGD', 'epochs': 78, 'n_layers': 2, 'hidden_dim': 37, 'dropout_rate': 0.4000135600453857, 'activation': 'leaky_relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:04:29,650] Trial 3 finished with value: 50.2561999404511 and parameters: {'batch_size': 16, 'lr': 0.003980128629354552, 'optimizer': 'SGD', 'epochs': 66, 'n_layers': 2, 'hidden_dim': 144, 'dropout_rate': 0.44061205910971457, 'activation': 'relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:04:48,393] Trial 4 finished with value: 97.19255635553871 and parameters: {'batch_size': 16, 'lr': 0.00017646874933277762, 'optimizer': 'SGD', 'epochs': 59, 'n_layers': 3, 'hidden_dim': 204, 'dropout_rate': 0.44541970006797593, 'activation': 'relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:04:58,556] Trial 5 finished with value: 62.39363294480679 and parameters: {'batch_size': 16, 'lr': 0.001495102708686965, 'optimizer': 'SGD', 'epochs': 36, 'n_layers': 2, 'hidden_dim': 202, 'dropout_rate': 0.27443955469510756, 'activation': 'relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:05:06,690] Trial 6 finished with value: 43.9553210679413 and parameters: {'batch_size': 16, 'lr': 0.0008976256676684966, 'optimizer': 'Adam', 'epochs': 40, 'n_layers': 2, 'hidden_dim': 85, 'dropout_rate': 0.25967485797570145, 'activation': 'leaky_relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:05:28,642] Trial 7 finished with value: 44.40825990540343 and parameters: {'batch_size': 16, 'lr': 0.00939551126024149, 'optimizer': 'SGD', 'epochs': 82, 'n_layers': 4, 'hidden_dim': 166, 'dropout_rate': 0.25144755513267647, 'activation': 'leaky_relu'}. Best is trial 1 with value: 42.43999237766509.\n",
      "[I 2025-07-03 21:05:32,022] Trial 8 finished with value: 39.78011892100981 and parameters: {'batch_size': 64, 'lr': 0.0013743684614948778, 'optimizer': 'Adam', 'epochs': 46, 'n_layers': 4, 'hidden_dim': 179, 'dropout_rate': 0.26226941899110123, 'activation': 'relu'}. Best is trial 8 with value: 39.78011892100981.\n",
      "[I 2025-07-03 21:05:40,829] Trial 9 finished with value: 84.56827580596764 and parameters: {'batch_size': 32, 'lr': 0.0002729531007326498, 'optimizer': 'SGD', 'epochs': 84, 'n_layers': 2, 'hidden_dim': 171, 'dropout_rate': 0.34238416592270005, 'activation': 'leaky_relu'}. Best is trial 8 with value: 39.78011892100981.\n",
      "[I 2025-07-03 21:05:43,105] Trial 10 finished with value: 41.456454776333466 and parameters: {'batch_size': 64, 'lr': 0.002214080184166193, 'optimizer': 'Adam', 'epochs': 50, 'n_layers': 4, 'hidden_dim': 242, 'dropout_rate': 0.12625554566108158, 'activation': 'relu'}. Best is trial 8 with value: 39.78011892100981.\n",
      "[I 2025-07-03 21:05:45,410] Trial 11 finished with value: 39.983625098047284 and parameters: {'batch_size': 64, 'lr': 0.001950997172673661, 'optimizer': 'Adam', 'epochs': 50, 'n_layers': 4, 'hidden_dim': 255, 'dropout_rate': 0.1328106218877074, 'activation': 'relu'}. Best is trial 8 with value: 39.78011892100981.\n",
      "[I 2025-07-03 21:05:48,470] Trial 12 finished with value: 39.81909523238405 and parameters: {'batch_size': 64, 'lr': 0.000742879076924878, 'optimizer': 'Adam', 'epochs': 49, 'n_layers': 4, 'hidden_dim': 253, 'dropout_rate': 0.13184672394418276, 'activation': 'relu'}. Best is trial 8 with value: 39.78011892100981.\n",
      "[I 2025-07-03 21:05:50,776] Trial 13 finished with value: 38.37864229626129 and parameters: {'batch_size': 64, 'lr': 0.0007159882185765599, 'optimizer': 'Adam', 'epochs': 31, 'n_layers': 3, 'hidden_dim': 213, 'dropout_rate': 0.20536190735059906, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:05:52,975] Trial 14 finished with value: 41.510581672802836 and parameters: {'batch_size': 64, 'lr': 0.0006788264761242439, 'optimizer': 'Adam', 'epochs': 30, 'n_layers': 3, 'hidden_dim': 205, 'dropout_rate': 0.2006900252662258, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:05:57,147] Trial 15 finished with value: 40.281851965716285 and parameters: {'batch_size': 64, 'lr': 0.0033456461167139014, 'optimizer': 'Adam', 'epochs': 41, 'n_layers': 3, 'hidden_dim': 215, 'dropout_rate': 0.19734616330230345, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:05:59,425] Trial 16 finished with value: 46.86401436989747 and parameters: {'batch_size': 64, 'lr': 0.0004810338625177257, 'optimizer': 'Adam', 'epochs': 32, 'n_layers': 3, 'hidden_dim': 108, 'dropout_rate': 0.2031796826949694, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:04,998] Trial 17 finished with value: 41.07467649588184 and parameters: {'batch_size': 32, 'lr': 0.001224938382063855, 'optimizer': 'Adam', 'epochs': 61, 'n_layers': 3, 'hidden_dim': 226, 'dropout_rate': 0.31453429801047317, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:07,010] Trial 18 finished with value: 41.37160112096485 and parameters: {'batch_size': 64, 'lr': 0.004152750165325086, 'optimizer': 'Adam', 'epochs': 43, 'n_layers': 4, 'hidden_dim': 184, 'dropout_rate': 0.17363759457610553, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:10,944] Trial 19 finished with value: 59.256135567067965 and parameters: {'batch_size': 64, 'lr': 0.00010011755734242181, 'optimizer': 'Adam', 'epochs': 56, 'n_layers': 3, 'hidden_dim': 134, 'dropout_rate': 0.3685837936457294, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:14,010] Trial 20 finished with value: 53.09328026829056 and parameters: {'batch_size': 64, 'lr': 0.0005200618794084602, 'optimizer': 'Adam', 'epochs': 46, 'n_layers': 3, 'hidden_dim': 78, 'dropout_rate': 0.49126433021504246, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:16,724] Trial 21 finished with value: 41.87569181444551 and parameters: {'batch_size': 64, 'lr': 0.000871764096586424, 'optimizer': 'Adam', 'epochs': 52, 'n_layers': 4, 'hidden_dim': 234, 'dropout_rate': 0.15688075303840332, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:19,519] Trial 22 finished with value: 39.123468776001246 and parameters: {'batch_size': 64, 'lr': 0.001285163884730763, 'optimizer': 'Adam', 'epochs': 36, 'n_layers': 4, 'hidden_dim': 187, 'dropout_rate': 0.10456662037544755, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:22,629] Trial 23 finished with value: 41.18409529004738 and parameters: {'batch_size': 64, 'lr': 0.001857421270251395, 'optimizer': 'Adam', 'epochs': 36, 'n_layers': 4, 'hidden_dim': 183, 'dropout_rate': 0.10063516137434957, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:25,707] Trial 24 finished with value: 40.21234096033382 and parameters: {'batch_size': 64, 'lr': 0.0012160102032752228, 'optimizer': 'Adam', 'epochs': 36, 'n_layers': 4, 'hidden_dim': 187, 'dropout_rate': 0.22086426030756837, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:32,910] Trial 25 finished with value: 41.960414707993536 and parameters: {'batch_size': 32, 'lr': 0.0003485836086350719, 'optimizer': 'Adam', 'epochs': 31, 'n_layers': 3, 'hidden_dim': 151, 'dropout_rate': 0.28154092177416284, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:35,962] Trial 26 finished with value: 40.40876333942098 and parameters: {'batch_size': 64, 'lr': 0.002667661255273947, 'optimizer': 'Adam', 'epochs': 43, 'n_layers': 4, 'hidden_dim': 218, 'dropout_rate': 0.22828387939525716, 'activation': 'leaky_relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:38,401] Trial 27 finished with value: 43.01703468477396 and parameters: {'batch_size': 64, 'lr': 0.006426628714122718, 'optimizer': 'Adam', 'epochs': 67, 'n_layers': 4, 'hidden_dim': 192, 'dropout_rate': 0.10017257590761036, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:41,356] Trial 28 finished with value: 42.10065670877256 and parameters: {'batch_size': 64, 'lr': 0.001219305556729368, 'optimizer': 'Adam', 'epochs': 37, 'n_layers': 3, 'hidden_dim': 169, 'dropout_rate': 0.16700319391734525, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:49,730] Trial 29 finished with value: 41.46246288566744 and parameters: {'batch_size': 32, 'lr': 0.0005736641012524226, 'optimizer': 'Adam', 'epochs': 45, 'n_layers': 4, 'hidden_dim': 154, 'dropout_rate': 0.2982624970639829, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:52,513] Trial 30 finished with value: 40.75486232977778 and parameters: {'batch_size': 64, 'lr': 0.006689991112997957, 'optimizer': 'Adam', 'epochs': 97, 'n_layers': 3, 'hidden_dim': 120, 'dropout_rate': 0.23224129532296225, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:06:55,949] Trial 31 finished with value: 42.159885346515 and parameters: {'batch_size': 64, 'lr': 0.0008104600414653641, 'optimizer': 'Adam', 'epochs': 54, 'n_layers': 4, 'hidden_dim': 253, 'dropout_rate': 0.13904079903055458, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:01,947] Trial 32 finished with value: 42.119363341666336 and parameters: {'batch_size': 64, 'lr': 0.0006910381840968069, 'optimizer': 'Adam', 'epochs': 49, 'n_layers': 4, 'hidden_dim': 237, 'dropout_rate': 0.1795901024684626, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:05,139] Trial 33 finished with value: 40.70934238737165 and parameters: {'batch_size': 64, 'lr': 0.0014761472801110402, 'optimizer': 'Adam', 'epochs': 71, 'n_layers': 4, 'hidden_dim': 228, 'dropout_rate': 0.12313596865962313, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:08,097] Trial 34 finished with value: 40.51018597301144 and parameters: {'batch_size': 64, 'lr': 0.0003574653957795581, 'optimizer': 'Adam', 'epochs': 39, 'n_layers': 4, 'hidden_dim': 217, 'dropout_rate': 0.1432046310368727, 'activation': 'leaky_relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:10,017] Trial 35 finished with value: 98.69932335767744 and parameters: {'batch_size': 64, 'lr': 0.0006783565511907458, 'optimizer': 'SGD', 'epochs': 33, 'n_layers': 4, 'hidden_dim': 197, 'dropout_rate': 0.18345707104777192, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:15,946] Trial 36 finished with value: 45.578354850077886 and parameters: {'batch_size': 32, 'lr': 0.0011072210605896032, 'optimizer': 'Adam', 'epochs': 60, 'n_layers': 4, 'hidden_dim': 32, 'dropout_rate': 0.15461908482767636, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:25,889] Trial 37 finished with value: 66.69845126619808 and parameters: {'batch_size': 16, 'lr': 0.0015691544591353106, 'optimizer': 'SGD', 'epochs': 47, 'n_layers': 3, 'hidden_dim': 247, 'dropout_rate': 0.2518501796709314, 'activation': 'leaky_relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:28,264] Trial 38 finished with value: 40.55819124956489 and parameters: {'batch_size': 64, 'lr': 0.0009798452000382488, 'optimizer': 'Adam', 'epochs': 34, 'n_layers': 3, 'hidden_dim': 209, 'dropout_rate': 0.1115194088717153, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:40,725] Trial 39 finished with value: 56.128243814803355 and parameters: {'batch_size': 16, 'lr': 0.0025286605066670953, 'optimizer': 'SGD', 'epochs': 40, 'n_layers': 2, 'hidden_dim': 173, 'dropout_rate': 0.21340568207410882, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:45,060] Trial 40 finished with value: 45.94970580507782 and parameters: {'batch_size': 64, 'lr': 0.00023160099110004027, 'optimizer': 'Adam', 'epochs': 56, 'n_layers': 4, 'hidden_dim': 156, 'dropout_rate': 0.28671128369966514, 'activation': 'leaky_relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:47,071] Trial 41 finished with value: 40.15786869595131 and parameters: {'batch_size': 64, 'lr': 0.0019569200325829116, 'optimizer': 'Adam', 'epochs': 51, 'n_layers': 4, 'hidden_dim': 248, 'dropout_rate': 0.13149050212241561, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:50,646] Trial 42 finished with value: 41.96687471344961 and parameters: {'batch_size': 64, 'lr': 0.001615126257635286, 'optimizer': 'Adam', 'epochs': 47, 'n_layers': 4, 'hidden_dim': 255, 'dropout_rate': 0.14611042796265072, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:54,342] Trial 43 finished with value: 40.73601210517013 and parameters: {'batch_size': 64, 'lr': 0.0008148085959903731, 'optimizer': 'Adam', 'epochs': 63, 'n_layers': 4, 'hidden_dim': 226, 'dropout_rate': 0.12578894664371965, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:07:56,938] Trial 44 finished with value: 39.758376586493235 and parameters: {'batch_size': 64, 'lr': 0.0027756094131445924, 'optimizer': 'Adam', 'epochs': 44, 'n_layers': 4, 'hidden_dim': 240, 'dropout_rate': 0.26628931189158256, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:08:10,909] Trial 45 finished with value: 67.25521699937259 and parameters: {'batch_size': 16, 'lr': 0.0034578412143194933, 'optimizer': 'SGD', 'epochs': 42, 'n_layers': 4, 'hidden_dim': 238, 'dropout_rate': 0.26831132998761603, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:08:14,065] Trial 46 finished with value: 45.04399094625522 and parameters: {'batch_size': 64, 'lr': 0.00043772743266196735, 'optimizer': 'Adam', 'epochs': 30, 'n_layers': 4, 'hidden_dim': 205, 'dropout_rate': 0.3173250118895966, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:08:16,545] Trial 47 finished with value: 42.872674661654514 and parameters: {'batch_size': 64, 'lr': 0.0044899170225652625, 'optimizer': 'Adam', 'epochs': 38, 'n_layers': 3, 'hidden_dim': 218, 'dropout_rate': 0.23656638318130446, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:08:22,536] Trial 48 finished with value: 45.93795527652206 and parameters: {'batch_size': 32, 'lr': 0.002796058784461047, 'optimizer': 'Adam', 'epochs': 34, 'n_layers': 4, 'hidden_dim': 201, 'dropout_rate': 0.34630505209939355, 'activation': 'leaky_relu'}. Best is trial 13 with value: 38.37864229626129.\n",
      "[I 2025-07-03 21:08:25,868] Trial 49 finished with value: 43.07010862201587 and parameters: {'batch_size': 64, 'lr': 0.0006078226250443346, 'optimizer': 'Adam', 'epochs': 87, 'n_layers': 3, 'hidden_dim': 176, 'dropout_rate': 0.2455999040522329, 'activation': 'relu'}. Best is trial 13 with value: 38.37864229626129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial : {'batch_size': 64, 'lr': 0.0007159882185765599, 'optimizer': 'Adam', 'epochs': 31, 'n_layers': 3, 'hidden_dim': 213, 'dropout_rate': 0.20536190735059906, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# 実行\n",
    "print(\"Optuna最適化開始...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # 試行回数を増やす\n",
    "\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b827d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 45.6510\n",
      "Fold MAE : 29.5482\n",
      "Fold R2  : 0.7745\n",
      "\n",
      "Fold RMSE : 48.6657\n",
      "Fold MAE : 33.2880\n",
      "Fold R2  : 0.8075\n",
      "\n",
      "Fold RMSE : 45.0280\n",
      "Fold MAE : 34.1156\n",
      "Fold R2  : 0.8035\n",
      "\n",
      "Fold RMSE : 40.4799\n",
      "Fold MAE : 29.1705\n",
      "Fold R2  : 0.7934\n",
      "\n",
      "Fold RMSE : 31.5687\n",
      "Fold MAE : 25.4763\n",
      "Fold R2  : 0.8773\n",
      "\n",
      "\n",
      "平均RMSE : 42.2787\n",
      "平均MAE  : 30.3197\n",
      "平均R2   : 0.8112\n"
     ]
    }
   ],
   "source": [
    "# 汎化性能チェック（修正版）\n",
    "print(\"\\n汎化性能評価開始...\")\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# 分割前に標準化\n",
    "X_scaler = StandardScaler()\n",
    "autoscaled_X = X_scaler.fit_transform(X_train_all)\n",
    "y_scaler = StandardScaler()\n",
    "autoscaled_y = y_scaler.fit_transform(y_train_all.values.reshape(-1, 1))\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(autoscaled_X)):\n",
    "    print(f\"Fold {fold + 1}/5\")\n",
    "    \n",
    "    # データ分割\n",
    "    X_train, X_val = autoscaled_X[train_index], autoscaled_X[val_index]\n",
    "    y_train, y_val = autoscaled_y[train_index], autoscaled_y[val_index]\n",
    "\n",
    "    # Dataset/DataLoader\n",
    "    train_ds = RegressionDataset(X_train, y_train)\n",
    "    val_ds = RegressionDataset(X_val, y_val)\n",
    "    train_dl = DataLoader(train_ds, batch_size=study.best_trial.params['batch_size'], shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=study.best_trial.params['batch_size'], shuffle=False)\n",
    "\n",
    "    # モデルと最適化\n",
    "    model_nn_op = define_model(study.best_trial, input_dim=X_train.shape[1]).to(device)\n",
    "    if study.best_trial.params['optimizer'] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model_nn_op.parameters(), lr=study.best_trial.params['lr'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model_nn_op.parameters(), lr=study.best_trial.params['lr'])\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # 学習（Early Stopping付き）\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(100):  # 最大エポック数\n",
    "        model_nn_op.train()\n",
    "        for X_batch, y_batch in train_dl:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model_nn_op(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 検証\n",
    "        val_loss = evaluate(model_nn_op, val_dl, device, y_scaler)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            \n",
    "        if no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    # 最終推論\n",
    "    model_nn_op.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_dl:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_std = model_nn_op(X_batch).cpu().numpy()\n",
    "            preds.append(y_pred_std)\n",
    "    \n",
    "    y_pred_std = np.vstack(preds)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_std).flatten()\n",
    "    y_true = y_scaler.inverse_transform(y_val).flatten()\n",
    "\n",
    "    # 評価\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE: {rmse:.4f}')\n",
    "    print(f'Fold MAE: {mae:.4f}')\n",
    "    print(f'Fold R2: {r2:.4f}\\n')\n",
    "\n",
    "# 平均結果出力\n",
    "print(f'\\n平均RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}')\n",
    "print(f'平均MAE: {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}')\n",
    "print(f'平均R2: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f42ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最終モデルの学習...\n",
      "最終モデルとスケーラーを保存しました。\n"
     ]
    }
   ],
   "source": [
    "# 最終モデルの学習と保存\n",
    "print(\"\\n最終モデルの学習...\")\n",
    "X_scaler_final = StandardScaler()\n",
    "X_train_scaled = X_scaler_final.fit_transform(X_train_all)\n",
    "y_scaler_final = StandardScaler()\n",
    "y_train_scaled = y_scaler_final.fit_transform(y_train_all.values.reshape(-1, 1))\n",
    "\n",
    "# 最終モデル\n",
    "final_model = define_model(study.best_trial, X_train_scaled.shape[1]).to(device)\n",
    "if study.best_trial.params['optimizer'] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=study.best_trial.params['lr'])\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(final_model.parameters(), lr=study.best_trial.params['lr'])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 全データで学習\n",
    "train_dataset = RegressionDataset(X_train_scaled, y_train_scaled)\n",
    "train_loader = DataLoader(train_dataset, batch_size=study.best_trial.params['batch_size'], shuffle=True)\n",
    "\n",
    "for epoch in range(study.best_trial.params.get('epochs', 50)):\n",
    "    train_epoch(final_model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "# モデルとスケーラーの保存\n",
    "torch.save(final_model.state_dict(), 'final_nn_model.pth')\n",
    "with open('scalers.pkl', 'wb') as f:\n",
    "    pickle.dump({'X_scaler': X_scaler_final, 'y_scaler': y_scaler_final}, f)\n",
    "\n",
    "print(\"最終モデルとスケーラーを保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ec25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_testの予測を開始...\n",
      "\n",
      "予測結果:\n",
      "  Material  Predicted_PL\n",
      "0    test1    553.840149\n",
      "1    test2    697.178528\n",
      "2    test3    620.509521\n",
      "3    test4    670.996704\n",
      "4    test5    625.717773\n"
     ]
    }
   ],
   "source": [
    "# 保存したモデルでX_testを予測\n",
    "print(\"\\nX_testの予測を開始...\")\n",
    "\n",
    "# X_testを標準化\n",
    "X_test_scaled = X_scaler_final.transform(X_test)\n",
    "\n",
    "# 予測用データセット（yはダミー）\n",
    "test_dataset = RegressionDataset(X_test_scaled, np.zeros(len(X_test_scaled)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 予測実行\n",
    "final_model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred_std = final_model(X_batch).cpu().numpy()\n",
    "        predictions.append(y_pred_std)\n",
    "\n",
    "# 予測結果をまとめる\n",
    "y_pred_std = np.vstack(predictions)\n",
    "y_pred = y_scaler_final.inverse_transform(y_pred_std).flatten()\n",
    "\n",
    "# 結果をデータフレームに格納\n",
    "results_df = pd.DataFrame({\n",
    "    'Material': X_test.index,\n",
    "    'Predicted_PL': y_pred\n",
    "})\n",
    "\n",
    "print(\"\\n予測結果:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込みモデルによる予測結果:\n",
      "  Material  Predicted_PL\n",
      "0    test1    553.840149\n",
      "1    test2    697.178528\n",
      "2    test3    620.509521\n",
      "3    test4    670.996704\n",
      "4    test5    625.717773\n"
     ]
    }
   ],
   "source": [
    "# ===== 別途：保存したモデルを読み込んで予測する場合 =====\n",
    "def load_model_and_predict(model_path, scaler_path, X_test_data):\n",
    "    \"\"\"\n",
    "    保存したモデルとスケーラーを読み込んで予測を行う関数\n",
    "    \n",
    "    Args:\n",
    "        model_path: 保存したモデルファイルのパス\n",
    "        scaler_path: 保存したスケーラーファイルのパス\n",
    "        X_test_data: 予測したいデータ\n",
    "    \n",
    "    Returns:\n",
    "        予測結果のDataFrame\n",
    "    \"\"\"\n",
    "    # スケーラーの読み込み\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scalers = pickle.load(f)\n",
    "    X_scaler = scalers['X_scaler']\n",
    "    y_scaler = scalers['y_scaler']\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    # 注意: モデルの構造は事前に定義されている必要があります\n",
    "    input_dim = X_test_data.shape[1]\n",
    "    model = define_model(study.best_trial, input_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))  # CPU専用\n",
    "    model.eval()\n",
    "    \n",
    "    # データの標準化\n",
    "    X_test_scaled = X_scaler.transform(X_test_data)\n",
    "    \n",
    "    # 予測用データセット\n",
    "    test_dataset = RegressionDataset(X_test_scaled, np.zeros(len(X_test_scaled)))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # 予測実行\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_std = model(X_batch).cpu().numpy()\n",
    "            predictions.append(y_pred_std)\n",
    "    \n",
    "    # 予測結果をまとめる\n",
    "    y_pred_std = np.vstack(predictions)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_std).flatten()\n",
    "    \n",
    "    # 結果をデータフレームに格納\n",
    "    results_df = pd.DataFrame({\n",
    "        'Material': X_test_data.index,\n",
    "        'Predicted_PL': y_pred\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2b85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol-regression-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
