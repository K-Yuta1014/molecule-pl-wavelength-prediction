{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035c650d",
   "metadata": {},
   "source": [
    "# CVをつかって汎化性能を評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ad6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/xgboost/compat.py:105: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import optuna\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b641991",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a4a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 3) (1258, 1427) (1258, 1430)\n"
     ]
    }
   ],
   "source": [
    "# 入力：読み込みたい記述子のタイプを選択\n",
    "descriptor_type = 'mordred_3d'  # 'rdkit' or 'mordred_2d' or 'mordred_3d'\n",
    "\n",
    "# ベースのデータ\n",
    "dataset = pd.read_csv('data/material_data.csv', index_col=0)\n",
    "\n",
    "# 条件に応じて記述子ファイルを読み込む\n",
    "if descriptor_type == \"rdkit\":\n",
    "    des = pd.read_csv(\"outputs/descriptors/descriptor_rdkit.csv\", index_col=0)\n",
    "elif descriptor_type == \"mordred_2d\":\n",
    "    des = pd.read_csv(\"outputs/descriptors/descriptor_mordred_2d.csv\", index_col=0)\n",
    "elif descriptor_type == \"mordred_3d\":\n",
    "    des = pd.read_csv(\"outputs/descriptors/descriptor_mordred_3d.csv\", index_col=0)\n",
    "else:\n",
    "    raise ValueError(f\"未知のdescriptor_type: {descriptor_type}\")\n",
    "\n",
    "# 結合\n",
    "dataset_full = pd.concat([dataset.reset_index(), des.reset_index(drop=True)], axis=1)\n",
    "dataset_full = dataset_full.set_index('Material')\n",
    "\n",
    "# 確認\n",
    "print(dataset.shape, des.shape, dataset_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9ffb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 1428)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLに欠損値が入っている行を消して、学習データのみにする\n",
    "dataset_train = dataset_full.dropna(subset='PL')\n",
    "# SMILESとTypeも消しておく\n",
    "dataset_train = dataset_train.drop(['SMILES', 'Type'], axis=1)\n",
    "\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcd9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 1220)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# infをNaNに置き換え\n",
    "dataset_train = dataset_train.replace(np.inf, np.nan).fillna(np.nan)\n",
    "dataset_train = dataset_train.drop(dataset_train.columns[dataset_train.isnull().any()], axis=1)\n",
    "\n",
    "# 標準偏差が0の記述を削除\n",
    "dataset_train = dataset_train.drop(dataset_train.columns[dataset_train.std() == 0], axis=1)\n",
    "\n",
    "# 学習データのstdが0の列を特定\n",
    "zero_std_cols = dataset_train.columns[dataset_train.std() == 0]\n",
    "\n",
    "# 学習・未知データから同じ列を削除\n",
    "dataset_train = dataset_train.drop(columns=zero_std_cols)\n",
    "\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a00333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数と説明変数に分ける\n",
    "y = dataset_train['PL']\n",
    "X = dataset_train.drop('PL', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893714d",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990b1ae",
   "metadata": {},
   "source": [
    "### PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f48dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 55.0048\n",
      "Fold MAE : 40.1641\n",
      "Fold R2 : 0.7112\n",
      "\n",
      "Fold RMSE : 39.1255\n",
      "Fold MAE : 29.4016\n",
      "Fold R2 : 0.8493\n",
      "\n",
      "Fold RMSE : 81.0496\n",
      "Fold MAE : 46.2467\n",
      "Fold R2 : 0.5356\n",
      "\n",
      "Fold RMSE : 45.6420\n",
      "Fold MAE : 36.4036\n",
      "Fold R2 : 0.8222\n",
      "\n",
      "Fold RMSE : 62.8705\n",
      "Fold MAE : 45.5084\n",
      "Fold R2 : 0.6139\n",
      "\n",
      "平均RMSE : 56.7385\n",
      "平均MAE : 39.5449\n",
      "平均R2 : 0.7064\n"
     ]
    }
   ],
   "source": [
    "# PLSモデルの構築\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model_pls = PLSRegression(n_components=6)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_pls.fit(autoscaled_X_train, autoscaled_y_train.values.ravel())\n",
    "    y_pred_scaled = model_pls.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b04f3",
   "metadata": {},
   "source": [
    "### PLS+optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f73aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_pls(trial):\n",
    "    # ハイパーパラメータ: 潜在変数の数\n",
    "    n_components = trial.suggest_int('n_components', 1, min(30, X.shape[1]))\n",
    "\n",
    "    # KFoldで分割\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 標準化（Xとy両方）\n",
    "        X_scaler = StandardScaler()\n",
    "        X_train_scaled = pd.DataFrame(X_scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "        X_val_scaled = pd.DataFrame(X_scaler.transform(X_val), index=X_val.index, columns=X_val.columns)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        y_train_scaled = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "\n",
    "        # モデル定義・学習\n",
    "        model = PLSRegression(n_components=n_components)\n",
    "        model.fit(X_train_scaled, y_train_scaled.values.ravel())\n",
    "\n",
    "        # 予測（スケールを戻す）\n",
    "        y_pred_scaled = model.predict(X_val_scaled)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeb8de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:16:08,621] A new study created in memory with name: no-name-08af5606-3f04-4c76-bab8-0f0607df6c7f\n",
      "[I 2025-08-06 21:16:08,953] Trial 0 finished with value: 58.06818154787377 and parameters: {'n_components': 7}. Best is trial 0 with value: 58.06818154787377.\n",
      "[I 2025-08-06 21:16:09,307] Trial 1 finished with value: 59.17286318559559 and parameters: {'n_components': 9}. Best is trial 0 with value: 58.06818154787377.\n",
      "[I 2025-08-06 21:16:09,871] Trial 2 finished with value: 66.53241318819937 and parameters: {'n_components': 19}. Best is trial 0 with value: 58.06818154787377.\n",
      "[I 2025-08-06 21:16:10,298] Trial 3 finished with value: 63.624355778202 and parameters: {'n_components': 16}. Best is trial 0 with value: 58.06818154787377.\n",
      "[I 2025-08-06 21:16:10,841] Trial 4 finished with value: 71.59664444198032 and parameters: {'n_components': 23}. Best is trial 0 with value: 58.06818154787377.\n",
      "[I 2025-08-06 21:16:11,193] Trial 5 finished with value: 56.839843254604226 and parameters: {'n_components': 5}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:11,899] Trial 6 finished with value: 70.76872047824952 and parameters: {'n_components': 22}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:12,724] Trial 7 finished with value: 71.59664444198032 and parameters: {'n_components': 23}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:14,481] Trial 8 finished with value: 71.59664444198032 and parameters: {'n_components': 23}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:16,218] Trial 9 finished with value: 74.20904228143397 and parameters: {'n_components': 28}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:16,476] Trial 10 finished with value: 83.07567728821607 and parameters: {'n_components': 1}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:16,850] Trial 11 finished with value: 58.06818154787377 and parameters: {'n_components': 7}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:17,194] Trial 12 finished with value: 59.17286318559559 and parameters: {'n_components': 9}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:17,506] Trial 13 finished with value: 83.07567728821607 and parameters: {'n_components': 1}. Best is trial 5 with value: 56.839843254604226.\n",
      "[I 2025-08-06 21:16:18,187] Trial 14 finished with value: 56.73847233522677 and parameters: {'n_components': 6}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:19,230] Trial 15 finished with value: 64.57553824907806 and parameters: {'n_components': 13}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:19,822] Trial 16 finished with value: 56.839843254604226 and parameters: {'n_components': 5}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:21,077] Trial 17 finished with value: 64.57553824907806 and parameters: {'n_components': 13}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:21,720] Trial 18 finished with value: 59.783557191097124 and parameters: {'n_components': 4}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:22,698] Trial 19 finished with value: 63.29980491664306 and parameters: {'n_components': 11}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:23,315] Trial 20 finished with value: 59.783557191097124 and parameters: {'n_components': 4}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:24,020] Trial 21 finished with value: 59.783557191097124 and parameters: {'n_components': 4}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:24,775] Trial 22 finished with value: 58.06818154787377 and parameters: {'n_components': 7}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:25,252] Trial 23 finished with value: 59.783557191097124 and parameters: {'n_components': 4}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:26,266] Trial 24 finished with value: 63.29980491664306 and parameters: {'n_components': 11}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:26,694] Trial 25 finished with value: 83.07567728821607 and parameters: {'n_components': 1}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:28,078] Trial 26 finished with value: 63.624355778202 and parameters: {'n_components': 16}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:28,873] Trial 27 finished with value: 56.73847233522677 and parameters: {'n_components': 6}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:29,513] Trial 28 finished with value: 59.17286318559559 and parameters: {'n_components': 9}. Best is trial 14 with value: 56.73847233522677.\n",
      "[I 2025-08-06 21:16:30,169] Trial 29 finished with value: 56.73847233522677 and parameters: {'n_components': 6}. Best is trial 14 with value: 56.73847233522677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_components': 6}\n",
      "Best RMSE: 56.73847233522677\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective_pls, n_trials=30)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4437585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 55.0048\n",
      "Fold MAE : 40.1641\n",
      "Fold R2 : 0.7112\n",
      "\n",
      "Fold RMSE : 39.1255\n",
      "Fold MAE : 29.4016\n",
      "Fold R2 : 0.8493\n",
      "\n",
      "Fold RMSE : 81.0496\n",
      "Fold MAE : 46.2467\n",
      "Fold R2 : 0.5356\n",
      "\n",
      "Fold RMSE : 45.6420\n",
      "Fold MAE : 36.4036\n",
      "Fold R2 : 0.8222\n",
      "\n",
      "Fold RMSE : 62.8705\n",
      "Fold MAE : 45.5084\n",
      "Fold R2 : 0.6139\n",
      "\n",
      "平均RMSE : 56.7385\n",
      "平均MAE : 39.5449\n",
      "平均R2 : 0.7064\n"
     ]
    }
   ],
   "source": [
    "# PLSモデルの構築\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model_pls = PLSRegression(**study.best_params)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_pls.fit(autoscaled_X_train, autoscaled_y_train.values.ravel())\n",
    "    y_pred_scaled = model_pls.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ebc76b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dca1825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 51.2594\n",
      "Fold MAE : 36.0020\n",
      "Fold R2 : 0.7491\n",
      "\n",
      "Fold RMSE : 44.5128\n",
      "Fold MAE : 31.6281\n",
      "Fold R2 : 0.8050\n",
      "\n",
      "Fold RMSE : 48.6313\n",
      "Fold MAE : 31.3504\n",
      "Fold R2 : 0.8328\n",
      "\n",
      "Fold RMSE : 47.4534\n",
      "Fold MAE : 32.8682\n",
      "Fold R2 : 0.8079\n",
      "\n",
      "Fold RMSE : 53.2576\n",
      "Fold MAE : 32.8291\n",
      "Fold R2 : 0.7229\n",
      "\n",
      "平均RMSE : 49.0229\n",
      "平均MAE : 32.9355\n",
      "平均R2 : 0.7835\n"
     ]
    }
   ],
   "source": [
    "# デフォルト\n",
    "model_rf = RandomForestRegressor(random_state=1234)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_rf.fit(autoscaled_X_train, autoscaled_y_train.values.ravel())\n",
    "    y_pred_scaled = model_rf.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cca89",
   "metadata": {},
   "source": [
    "### RandomForest+Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0480e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    # 検証するパラメータ\n",
    "    params = {\n",
    "    \"n_estimators\" : trial.suggest_int('n_estimators', 5, 1000),\n",
    "    \"max_depth\" : trial.suggest_int('max_depth', 3, 50),\n",
    "    \"min_samples_split\" : trial.suggest_int('min_samples_split', 2, 10),\n",
    "    \"min_samples_leaf\" : trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "    \"max_features\" : trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "    'random_state' : 0,\n",
    "    'n_jobs' : -1,\n",
    "\n",
    "    }\n",
    "\n",
    "    # モデル定義\n",
    "    model_rf = RandomForestRegressor(**params)\n",
    "\n",
    "    # 分割、CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "    # 評価指標\n",
    "    rmse_scores = []\n",
    "    # mae_scores = []\n",
    "    # r2_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # 訓練と検証に分類\n",
    "        X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 標準化、DataFrameに戻す\n",
    "        X_scaler = StandardScaler()\n",
    "        autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "        autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "        autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "        # 学習&予測\n",
    "        model_rf.fit(autoscaled_X_train, autoscaled_y_train)\n",
    "        y_pred_scaled = model_rf.predict(autoscaled_X_val)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "        # 性能チェック\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        # mae = mean_absolute_error(y_val, y_pred)\n",
    "        # r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # 結果格納\n",
    "        rmse_scores.append(rmse)\n",
    "        # mae_scores.append(mae)\n",
    "        # r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(rmse_scores)  # 最適化したい評価指標を選ぶ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd25c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:17:04,042] A new study created in memory with name: regression\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:11,073] Trial 0 finished with value: 58.658152620834265 and parameters: {'n_estimators': 657, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 58.658152620834265.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:14,742] Trial 1 finished with value: 48.54104783302864 and parameters: {'n_estimators': 303, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 1 with value: 48.54104783302864.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:23,562] Trial 2 finished with value: 52.37240763958711 and parameters: {'n_estimators': 823, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 1 with value: 48.54104783302864.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:43,257] Trial 3 finished with value: 49.59257616280824 and parameters: {'n_estimators': 711, 'max_depth': 35, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 1 with value: 48.54104783302864.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:53,213] Trial 4 finished with value: 47.78072165958461 and parameters: {'n_estimators': 968, 'max_depth': 31, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:54,126] Trial 5 finished with value: 52.08390102158349 and parameters: {'n_estimators': 19, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:17:56,306] Trial 6 finished with value: 49.78961239073853 and parameters: {'n_estimators': 179, 'max_depth': 33, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:02,624] Trial 7 finished with value: 55.77328225366841 and parameters: {'n_estimators': 611, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:21,323] Trial 8 finished with value: 49.11185462246603 and parameters: {'n_estimators': 563, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:21,915] Trial 9 finished with value: 56.97558533897679 and parameters: {'n_estimators': 27, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:32,348] Trial 10 finished with value: 48.08251536203939 and parameters: {'n_estimators': 994, 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:42,344] Trial 11 finished with value: 48.08561169319078 and parameters: {'n_estimators': 943, 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:18:52,493] Trial 12 finished with value: 48.24989698627301 and parameters: {'n_estimators': 931, 'max_depth': 44, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 47.78072165958461.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:02,897] Trial 13 finished with value: 47.67654658501702 and parameters: {'n_estimators': 968, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 13 with value: 47.67654658501702.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:07,078] Trial 14 finished with value: 48.02928418858191 and parameters: {'n_estimators': 381, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 13 with value: 47.67654658501702.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:15,615] Trial 15 finished with value: 47.60897918969768 and parameters: {'n_estimators': 796, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:24,105] Trial 16 finished with value: 50.29720795510143 and parameters: {'n_estimators': 789, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:32,364] Trial 17 finished with value: 55.12141887799184 and parameters: {'n_estimators': 814, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:40,171] Trial 18 finished with value: 48.44331071689034 and parameters: {'n_estimators': 741, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:19:52,896] Trial 19 finished with value: 49.19242543455043 and parameters: {'n_estimators': 438, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:02,514] Trial 20 finished with value: 47.84947993031382 and parameters: {'n_estimators': 861, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:13,003] Trial 21 finished with value: 47.694124177731105 and parameters: {'n_estimators': 904, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:22,773] Trial 22 finished with value: 47.66399689985849 and parameters: {'n_estimators': 891, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:30,903] Trial 23 finished with value: 47.83836718216082 and parameters: {'n_estimators': 723, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:40,406] Trial 24 finished with value: 47.68361153471726 and parameters: {'n_estimators': 873, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:50,949] Trial 25 finished with value: 55.00562229131216 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:20:57,171] Trial 26 finished with value: 49.83647155445901 and parameters: {'n_estimators': 545, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:04,662] Trial 27 finished with value: 47.83968517553341 and parameters: {'n_estimators': 661, 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:12,887] Trial 28 finished with value: 56.72920667146434 and parameters: {'n_estimators': 781, 'max_depth': 38, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:26,054] Trial 29 finished with value: 50.928886078282446 and parameters: {'n_estimators': 662, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:34,398] Trial 30 finished with value: 50.36428245122998 and parameters: {'n_estimators': 831, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:44,266] Trial 31 finished with value: 47.739402955052945 and parameters: {'n_estimators': 914, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:21:53,519] Trial 32 finished with value: 47.66223374633002 and parameters: {'n_estimators': 859, 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 47.60897918969768.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:03,197] Trial 33 finished with value: 47.222215296197206 and parameters: {'n_estimators': 867, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:11,595] Trial 34 finished with value: 47.32610726902502 and parameters: {'n_estimators': 756, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:19,661] Trial 35 finished with value: 48.67765305120712 and parameters: {'n_estimators': 758, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:27,067] Trial 36 finished with value: 47.77198394191111 and parameters: {'n_estimators': 690, 'max_depth': 37, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:49,221] Trial 37 finished with value: 49.06256430065496 and parameters: {'n_estimators': 606, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:22:57,855] Trial 38 finished with value: 49.964133653021854 and parameters: {'n_estimators': 836, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:03,020] Trial 39 finished with value: 48.918722896282176 and parameters: {'n_estimators': 489, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:06,457] Trial 40 finished with value: 47.619757838596016 and parameters: {'n_estimators': 286, 'max_depth': 33, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:08,953] Trial 41 finished with value: 47.62720795112474 and parameters: {'n_estimators': 210, 'max_depth': 34, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:11,508] Trial 42 finished with value: 47.55533718080436 and parameters: {'n_estimators': 222, 'max_depth': 36, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:14,590] Trial 43 finished with value: 47.7523748057153 and parameters: {'n_estimators': 265, 'max_depth': 41, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:15,955] Trial 44 finished with value: 47.41725948119033 and parameters: {'n_estimators': 95, 'max_depth': 37, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:17,027] Trial 45 finished with value: 48.781417836898946 and parameters: {'n_estimators': 68, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:22,049] Trial 46 finished with value: 49.12909788328026 and parameters: {'n_estimators': 146, 'max_depth': 41, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:23,553] Trial 47 finished with value: 53.88223573076922 and parameters: {'n_estimators': 109, 'max_depth': 46, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:24,150] Trial 48 finished with value: 52.69118717436927 and parameters: {'n_estimators': 17, 'max_depth': 37, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-08-06 21:23:27,949] Trial 49 finished with value: 47.54713429016741 and parameters: {'n_estimators': 329, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 47.222215296197206.\n"
     ]
    }
   ],
   "source": [
    "# 最適化\n",
    "study = optuna.create_study(direction='minimize', study_name='regression')\n",
    "study.optimize(objective_rf, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b21f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  RMSE: 47.2222\n",
      "  Params:\n",
      "    n_estimators: 867\n",
      "    max_depth: 24\n",
      "    min_samples_split: 5\n",
      "    min_samples_leaf: 1\n",
      "    max_features: sqrt\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ・スコアの確認\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  RMSE: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "804b4216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 47.4713\n",
      "Fold MAE : 36.6037\n",
      "Fold R2 : 0.7849\n",
      "\n",
      "Fold RMSE : 44.9971\n",
      "Fold MAE : 32.7044\n",
      "Fold R2 : 0.8007\n",
      "\n",
      "Fold RMSE : 50.6210\n",
      "Fold MAE : 34.2110\n",
      "Fold R2 : 0.8188\n",
      "\n",
      "Fold RMSE : 52.3166\n",
      "Fold MAE : 39.0137\n",
      "Fold R2 : 0.7665\n",
      "\n",
      "Fold RMSE : 42.8248\n",
      "Fold MAE : 30.2876\n",
      "Fold R2 : 0.8209\n",
      "\n",
      "平均RMSE : 47.6462\n",
      "平均MAE : 34.5641\n",
      "平均R2 : 0.7983\n"
     ]
    }
   ],
   "source": [
    "# optunaで最適化されたパラメータをセットし、予測\n",
    "model_rf_op = RandomForestRegressor(**study.best_params)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習&予測\n",
    "    model_rf_op.fit(autoscaled_X_train, autoscaled_y_train.values.ravel())\n",
    "    y_pred_scaled = model_rf_op.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c48ca0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf/y_scaler.pkl']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最終モデルの構築\n",
    "model_rf_final = RandomForestRegressor(**study.best_params)\n",
    "\n",
    "# すべての学習データを標準化して、学習させる\n",
    "X_scaler_final = StandardScaler()\n",
    "y_scaler_final = StandardScaler()\n",
    "autoscaled_X = X_scaler_final.fit_transform(X)\n",
    "autoscaled_y = y_scaler_final.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# 学習\n",
    "model_rf_final = model_rf_final.fit(autoscaled_X, autoscaled_y.ravel())\n",
    "\n",
    "# ディレクトリ作成（なければ）\n",
    "os.makedirs('models/rf', exist_ok=True)\n",
    "\n",
    "# モデルとスケーラーの保存（joblib使用）\n",
    "joblib.dump(model_rf_final, 'models/rf/model_rf.pkl')\n",
    "joblib.dump(X_scaler_final, 'models/rf/X_scaler.pkl')\n",
    "joblib.dump(y_scaler_final, 'models/rf/y_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e35a98",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de034473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 56.0942\n",
      "Fold MAE : 34.3792\n",
      "Fold R2 : 0.6996\n",
      "\n",
      "Fold RMSE : 43.7661\n",
      "Fold MAE : 29.1311\n",
      "Fold R2 : 0.8115\n",
      "\n",
      "Fold RMSE : 57.9358\n",
      "Fold MAE : 40.7227\n",
      "Fold R2 : 0.7627\n",
      "\n",
      "Fold RMSE : 48.3889\n",
      "Fold MAE : 30.4412\n",
      "Fold R2 : 0.8002\n",
      "\n",
      "Fold RMSE : 55.5638\n",
      "Fold MAE : 34.8252\n",
      "Fold R2 : 0.6984\n",
      "\n",
      "平均RMSE : 52.3498\n",
      "平均MAE : 33.8999\n",
      "平均R2 : 0.7545\n"
     ]
    }
   ],
   "source": [
    "# 初手\n",
    "# デフォルトXGB\n",
    "model_xgb = xgb.XGBRegressor(random_state=1234)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_xgb.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)], verbose=0)\n",
    "    y_pred_scaled = model_xgb.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}\\n')\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c19cf",
   "metadata": {},
   "source": [
    "- RFより若干良い？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97097d2",
   "metadata": {},
   "source": [
    "### XGBoost+optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6e48e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # ハイパーパラメータのサンプリング\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 1234,\n",
    "        'tree_method': 'hist',  # gpu_histだとエラー出た\n",
    "    }\n",
    "\n",
    "    # モデル定義\n",
    "    model_xgb = xgb.XGBRegressor(**params)\n",
    "\n",
    "    # 分割、CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "    # 評価指標\n",
    "    rmse_scores = []\n",
    "    # mae_scores = []\n",
    "    # r2_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # 訓練と検証に分類\n",
    "        X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 標準化、DataFrameに戻す\n",
    "        X_scaler = StandardScaler()\n",
    "        autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "        autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "        autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "        # 学習\n",
    "        model_xgb.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)], verbose=0)\n",
    "        y_pred_scaled = model_xgb.predict(autoscaled_X_val)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "        # 性能チェック\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        # mae = mean_absolute_error(y_val, y_pred)\n",
    "        # r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # 結果格納\n",
    "        rmse_scores.append(rmse)\n",
    "        # mae_scores.append(mae)\n",
    "        # r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(rmse_scores)  # 最適化したい評価指標を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "594ecb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:23:50,505] A new study created in memory with name: regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:24:08,910] Trial 0 finished with value: 65.23266144683647 and parameters: {'n_estimators': 182, 'max_depth': 3, 'learning_rate': 0.006087660706064375, 'subsample': 0.8139662514785513, 'colsample_bytree': 0.792103872776475, 'reg_alpha': 2.202878084801497, 'reg_lambda': 0.004431468206482492}. Best is trial 0 with value: 65.23266144683647.\n",
      "[I 2025-08-06 21:24:28,572] Trial 1 finished with value: 88.55277319458571 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.0038650220964551096, 'subsample': 0.9758788724737484, 'colsample_bytree': 0.5527691452618815, 'reg_alpha': 0.0016042001284223455, 'reg_lambda': 4.345603173242743e-08}. Best is trial 0 with value: 65.23266144683647.\n",
      "[I 2025-08-06 21:24:34,219] Trial 2 finished with value: 56.14249083753706 and parameters: {'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.023262200685475663, 'subsample': 0.6846700763806285, 'colsample_bytree': 0.5071005496152201, 'reg_alpha': 9.669644438936276e-05, 'reg_lambda': 1.5812251965650082e-07}. Best is trial 2 with value: 56.14249083753706.\n",
      "[I 2025-08-06 21:24:53,455] Trial 3 finished with value: 48.908887375339944 and parameters: {'n_estimators': 160, 'max_depth': 4, 'learning_rate': 0.13875772056926491, 'subsample': 0.8135403016870874, 'colsample_bytree': 0.7645962249262307, 'reg_alpha': 0.035799344622057194, 'reg_lambda': 2.660057300327966e-05}. Best is trial 3 with value: 48.908887375339944.\n",
      "[I 2025-08-06 21:25:54,852] Trial 4 finished with value: 90.56738924138182 and parameters: {'n_estimators': 223, 'max_depth': 8, 'learning_rate': 0.0017725336021812027, 'subsample': 0.8976586339726679, 'colsample_bytree': 0.9125000629328941, 'reg_alpha': 0.2434029236726893, 'reg_lambda': 0.5141548490745771}. Best is trial 3 with value: 48.908887375339944.\n",
      "[I 2025-08-06 21:27:59,886] Trial 5 finished with value: 65.98912025945438 and parameters: {'n_estimators': 249, 'max_depth': 8, 'learning_rate': 0.0037476412490277987, 'subsample': 0.7896184794076537, 'colsample_bytree': 0.775053399327903, 'reg_alpha': 0.0003785298208215014, 'reg_lambda': 3.908599847623191e-05}. Best is trial 3 with value: 48.908887375339944.\n",
      "[I 2025-08-06 21:28:52,113] Trial 6 finished with value: 80.34659736670042 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.002946718690384045, 'subsample': 0.9843991378573402, 'colsample_bytree': 0.6820584749763927, 'reg_alpha': 8.129126893495177e-06, 'reg_lambda': 0.002009383638468571}. Best is trial 3 with value: 48.908887375339944.\n",
      "[I 2025-08-06 21:29:34,672] Trial 7 finished with value: 49.98978783051261 and parameters: {'n_estimators': 252, 'max_depth': 8, 'learning_rate': 0.17301458888488322, 'subsample': 0.8284556207910386, 'colsample_bytree': 0.8088673178526686, 'reg_alpha': 0.06843282413113719, 'reg_lambda': 0.002631714756091001}. Best is trial 3 with value: 48.908887375339944.\n",
      "[I 2025-08-06 21:29:54,773] Trial 8 finished with value: 47.69839624504732 and parameters: {'n_estimators': 266, 'max_depth': 3, 'learning_rate': 0.061089930943834594, 'subsample': 0.9948170356822974, 'colsample_bytree': 0.6987429387379486, 'reg_alpha': 7.519068925388987e-08, 'reg_lambda': 9.513500327353426e-06}. Best is trial 8 with value: 47.69839624504732.\n",
      "[I 2025-08-06 21:30:20,796] Trial 9 finished with value: 71.07762515456425 and parameters: {'n_estimators': 280, 'max_depth': 3, 'learning_rate': 0.0030592517685574076, 'subsample': 0.560227825145238, 'colsample_bytree': 0.8190526225494424, 'reg_alpha': 0.0016657632519874938, 'reg_lambda': 0.67472952750046}. Best is trial 8 with value: 47.69839624504732.\n",
      "[I 2025-08-06 21:32:42,430] Trial 10 finished with value: 47.74381505431677 and parameters: {'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.029555024902339893, 'subsample': 0.6664474998431945, 'colsample_bytree': 0.6390286983730566, 'reg_alpha': 1.4936602430575996e-08, 'reg_lambda': 1.651619991788722e-06}. Best is trial 8 with value: 47.69839624504732.\n",
      "[I 2025-08-06 21:34:46,606] Trial 11 finished with value: 47.05365748431997 and parameters: {'n_estimators': 298, 'max_depth': 10, 'learning_rate': 0.04233481180799426, 'subsample': 0.6388403454929644, 'colsample_bytree': 0.6458422033346144, 'reg_alpha': 1.8465985759519578e-08, 'reg_lambda': 1.9186015673305474e-06}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:36:33,304] Trial 12 finished with value: 48.14258251913656 and parameters: {'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.06407296051751166, 'subsample': 0.5543264076846766, 'colsample_bytree': 0.6367380296354999, 'reg_alpha': 1.7079342600898077e-08, 'reg_lambda': 2.6764337788001143e-06}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:37:09,521] Trial 13 finished with value: 48.080691088145485 and parameters: {'n_estimators': 227, 'max_depth': 6, 'learning_rate': 0.05806428391183549, 'subsample': 0.65024498057652, 'colsample_bytree': 0.6951497322955338, 'reg_alpha': 4.4569296741137937e-07, 'reg_lambda': 5.158615941993794e-07}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:39:24,220] Trial 14 finished with value: 49.28490002186011 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.009405015563053168, 'subsample': 0.7177414557989018, 'colsample_bytree': 0.5779595141162694, 'reg_alpha': 5.742459552271468e-07, 'reg_lambda': 1.2567203075961241e-08}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:40:06,429] Trial 15 finished with value: 48.801566016476684 and parameters: {'n_estimators': 215, 'max_depth': 7, 'learning_rate': 0.066703095243659, 'subsample': 0.6082931654724937, 'colsample_bytree': 0.6966036631115842, 'reg_alpha': 2.9400761280125435e-07, 'reg_lambda': 4.138323779292807e-05}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:40:30,687] Trial 16 finished with value: 51.44154126791462 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.013995549243209523, 'subsample': 0.5097801603504815, 'colsample_bytree': 0.8882660297946933, 'reg_alpha': 8.25793219229178e-06, 'reg_lambda': 7.488492037639436e-06}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:41:21,656] Trial 17 finished with value: 50.051411926181075 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.03658614826094606, 'subsample': 0.900697310426943, 'colsample_bytree': 0.9701793757852627, 'reg_alpha': 6.891877944352088e-08, 'reg_lambda': 0.000318448874659212}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:41:57,219] Trial 18 finished with value: 55.93363791906878 and parameters: {'n_estimators': 204, 'max_depth': 7, 'learning_rate': 0.29398360774253685, 'subsample': 0.7388242189607609, 'colsample_bytree': 0.6134501836286828, 'reg_alpha': 3.6761183113712277e-06, 'reg_lambda': 0.05076144590926354}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:42:56,063] Trial 19 finished with value: 53.06533279596399 and parameters: {'n_estimators': 241, 'max_depth': 9, 'learning_rate': 0.11723784983130205, 'subsample': 0.9225167724279517, 'colsample_bytree': 0.7068265784102613, 'reg_alpha': 3.856671047072172e-05, 'reg_lambda': 0.0002452441104620351}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:43:28,859] Trial 20 finished with value: 47.11818037173252 and parameters: {'n_estimators': 296, 'max_depth': 4, 'learning_rate': 0.017610031734633595, 'subsample': 0.6090275709152239, 'colsample_bytree': 0.8602420280521965, 'reg_alpha': 2.0176336769336615e-07, 'reg_lambda': 3.345177669276871e-07}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:44:03,151] Trial 21 finished with value: 47.72661133983446 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.010604669048449382, 'subsample': 0.6124073079420895, 'colsample_bytree': 0.8478270157464405, 'reg_alpha': 1.1310520145718067e-07, 'reg_lambda': 2.6865134806903687e-07}. Best is trial 11 with value: 47.05365748431997.\n",
      "[I 2025-08-06 21:44:30,373] Trial 22 finished with value: 45.131878681629686 and parameters: {'n_estimators': 277, 'max_depth': 4, 'learning_rate': 0.03942285559205853, 'subsample': 0.6292943045363016, 'colsample_bytree': 0.731591210376261, 'reg_alpha': 1.5223419238587428e-08, 'reg_lambda': 9.92417569145249}. Best is trial 22 with value: 45.131878681629686.\n",
      "[I 2025-08-06 21:44:59,850] Trial 23 finished with value: 45.26767175116214 and parameters: {'n_estimators': 277, 'max_depth': 4, 'learning_rate': 0.017804997055612597, 'subsample': 0.6069881613932542, 'colsample_bytree': 0.9937852095355213, 'reg_alpha': 1.0253480438831144e-08, 'reg_lambda': 4.599428327978164}. Best is trial 22 with value: 45.131878681629686.\n",
      "[I 2025-08-06 21:45:29,415] Trial 24 finished with value: 45.00687139463445 and parameters: {'n_estimators': 281, 'max_depth': 4, 'learning_rate': 0.03967755442005596, 'subsample': 0.548798239497751, 'colsample_bytree': 0.9465726152813247, 'reg_alpha': 1.0207791933863692e-08, 'reg_lambda': 9.919746214632324}. Best is trial 24 with value: 45.00687139463445.\n",
      "[I 2025-08-06 21:45:56,627] Trial 25 finished with value: 46.37756168528199 and parameters: {'n_estimators': 236, 'max_depth': 4, 'learning_rate': 0.019399509169906782, 'subsample': 0.5041501722770692, 'colsample_bytree': 0.9911923339430114, 'reg_alpha': 1.9728908451104013e-06, 'reg_lambda': 5.2184031493600775}. Best is trial 24 with value: 45.00687139463445.\n",
      "[I 2025-08-06 21:46:35,207] Trial 26 finished with value: 44.86861713323094 and parameters: {'n_estimators': 274, 'max_depth': 5, 'learning_rate': 0.02861790659974872, 'subsample': 0.5585990035465763, 'colsample_bytree': 0.9454726083312922, 'reg_alpha': 1.362661959560019e-08, 'reg_lambda': 8.861825605411882}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:46:59,877] Trial 27 finished with value: 48.61085885012255 and parameters: {'n_estimators': 206, 'max_depth': 5, 'learning_rate': 0.09925416021499063, 'subsample': 0.555341151124893, 'colsample_bytree': 0.9376990832852623, 'reg_alpha': 9.039575949357965e-07, 'reg_lambda': 0.4767873005626764}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:47:43,443] Trial 28 finished with value: 46.98004336599997 and parameters: {'n_estimators': 278, 'max_depth': 6, 'learning_rate': 0.03753236791937344, 'subsample': 0.5356165153761125, 'colsample_bytree': 0.7362381122041166, 'reg_alpha': 5.3369298279305947e-08, 'reg_lambda': 0.06756868643106989}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:48:06,367] Trial 29 finished with value: 67.85201198802386 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.006976542441860563, 'subsample': 0.7044925848853814, 'colsample_bytree': 0.9495482823782897, 'reg_alpha': 2.219269463191289, 'reg_lambda': 7.5002704343313455}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:48:17,363] Trial 30 finished with value: 46.90571554153556 and parameters: {'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.08627573578909045, 'subsample': 0.5741955745448891, 'colsample_bytree': 0.906370553746776, 'reg_alpha': 4.7155190355272527e-08, 'reg_lambda': 0.05118127278047426}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:48:45,635] Trial 31 finished with value: 45.11388358932349 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.027204224316818376, 'subsample': 0.5921743193269766, 'colsample_bytree': 0.9707003084400885, 'reg_alpha': 1.447996028434517e-08, 'reg_lambda': 2.1379878760607713}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:49:11,008] Trial 32 finished with value: 45.12074997247313 and parameters: {'n_estimators': 258, 'max_depth': 4, 'learning_rate': 0.02666097887872403, 'subsample': 0.5834085881359286, 'colsample_bytree': 0.9427932137977042, 'reg_alpha': 3.3958985508998005e-08, 'reg_lambda': 2.2949335616774516}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:49:45,267] Trial 33 finished with value: 45.99015722408717 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.02483374441425345, 'subsample': 0.5891400690067561, 'colsample_bytree': 0.9371360941464638, 'reg_alpha': 2.1237295554296537e-07, 'reg_lambda': 1.5839210819910383}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:49:52,350] Trial 34 finished with value: 70.6375308194716 and parameters: {'n_estimators': 63, 'max_depth': 4, 'learning_rate': 0.013319296480714532, 'subsample': 0.5292488848728509, 'colsample_bytree': 0.8850246755021554, 'reg_alpha': 5.4853287278027484e-08, 'reg_lambda': 0.15275960670351107}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:50:11,177] Trial 35 finished with value: 44.97506645961754 and parameters: {'n_estimators': 260, 'max_depth': 3, 'learning_rate': 0.027254649001444392, 'subsample': 0.6789111742923413, 'colsample_bytree': 0.9679684615101594, 'reg_alpha': 7.092082923227786e-07, 'reg_lambda': 1.8054722188093124}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:50:20,064] Trial 36 finished with value: 77.48635440607232 and parameters: {'n_estimators': 106, 'max_depth': 3, 'learning_rate': 0.006185281607712237, 'subsample': 0.68360035506255, 'colsample_bytree': 0.9684661097454743, 'reg_alpha': 1.816554006588804e-06, 'reg_lambda': 0.26634084577639705}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:50:36,419] Trial 37 finished with value: 46.55497022811829 and parameters: {'n_estimators': 234, 'max_depth': 3, 'learning_rate': 0.048607914882202896, 'subsample': 0.7684104174741906, 'colsample_bytree': 0.9086031280691875, 'reg_alpha': 2.6352056331463858e-05, 'reg_lambda': 0.0209407635432678}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:50:56,693] Trial 38 finished with value: 95.2184615544027 and parameters: {'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.001224791070879191, 'subsample': 0.524997838554825, 'colsample_bytree': 0.8526514390519174, 'reg_alpha': 0.0022190972312354836, 'reg_lambda': 1.249712129761224}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:51:45,362] Trial 39 finished with value: 47.519439928191034 and parameters: {'n_estimators': 244, 'max_depth': 6, 'learning_rate': 0.0299310096922778, 'subsample': 0.6634655623829986, 'colsample_bytree': 0.9998327259846481, 'reg_alpha': 0.000523353372517782, 'reg_lambda': 0.006724712348636088}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:52:26,452] Trial 40 finished with value: 49.68690509188337 and parameters: {'n_estimators': 265, 'max_depth': 5, 'learning_rate': 0.009153152294593932, 'subsample': 0.6947432081051638, 'colsample_bytree': 0.958791063907432, 'reg_alpha': 1.4020923238710915e-07, 'reg_lambda': 2.2591036494281918}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:52:51,967] Trial 41 finished with value: 45.64866901302132 and parameters: {'n_estimators': 255, 'max_depth': 4, 'learning_rate': 0.024227781669779447, 'subsample': 0.581307074575315, 'colsample_bytree': 0.9299420367115095, 'reg_alpha': 2.5618426559079066e-08, 'reg_lambda': 1.4194281003686267}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:53:20,352] Trial 42 finished with value: 45.07584614402031 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.02988126562347385, 'subsample': 0.5708093592067236, 'colsample_bytree': 0.9721354416054618, 'reg_alpha': 3.777137959162818e-08, 'reg_lambda': 3.6118762987068127}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:53:41,895] Trial 43 finished with value: 45.92866200067536 and parameters: {'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.014027013366612152, 'subsample': 0.5471017498489414, 'colsample_bytree': 0.9719394011103577, 'reg_alpha': 1.140262373860307e-08, 'reg_lambda': 0.22872860084145102}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:54:08,424] Trial 44 finished with value: 46.351158135221944 and parameters: {'n_estimators': 286, 'max_depth': 4, 'learning_rate': 0.0501410423722105, 'subsample': 0.6326164179815233, 'colsample_bytree': 0.8837260582708296, 'reg_alpha': 9.498626955439054e-07, 'reg_lambda': 0.6327899147074305}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:54:28,087] Trial 45 finished with value: 46.56526863230094 and parameters: {'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.03228435272000904, 'subsample': 0.8199043608325214, 'colsample_bytree': 0.9180288553189667, 'reg_alpha': 0.009672046110528864, 'reg_lambda': 3.804107667772919}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:54:59,799] Trial 46 finished with value: 46.826005776957395 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.07603823483883082, 'subsample': 0.5629031705394265, 'colsample_bytree': 0.7952453714574994, 'reg_alpha': 1.1161291508579442e-07, 'reg_lambda': 0.7846362015200409}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:55:14,699] Trial 47 finished with value: 50.0712329645068 and parameters: {'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.020774915006208552, 'subsample': 0.8485142793764399, 'colsample_bytree': 0.8271191266064324, 'reg_alpha': 7.508083711644889, 'reg_lambda': 7.9358742386079975}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:55:41,992] Trial 48 finished with value: 48.26903955916419 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.15752713557294154, 'subsample': 0.6574992311565838, 'colsample_bytree': 0.5074085488491356, 'reg_alpha': 2.995816485669494e-08, 'reg_lambda': 0.1488074151107863}. Best is trial 26 with value: 44.86861713323094.\n",
      "[I 2025-08-06 21:56:24,224] Trial 49 finished with value: 49.0863537386982 and parameters: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.048502588269888125, 'subsample': 0.5935488531890308, 'colsample_bytree': 0.9807973224046046, 'reg_alpha': 2.9835499514342214e-07, 'reg_lambda': 0.01435710617839719}. Best is trial 26 with value: 44.86861713323094.\n"
     ]
    }
   ],
   "source": [
    "# 最適化\n",
    "study = optuna.create_study(direction='minimize', study_name='regression')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2aa5693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  RMSE: 44.8686\n",
      "  Params:\n",
      "    n_estimators: 274\n",
      "    max_depth: 5\n",
      "    learning_rate: 0.02861790659974872\n",
      "    subsample: 0.5585990035465763\n",
      "    colsample_bytree: 0.9454726083312922\n",
      "    reg_alpha: 1.362661959560019e-08\n",
      "    reg_lambda: 8.861825605411882\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ・スコアの確認\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  RMSE: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f3d6a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 46.1361\n",
      "Fold MAE : 32.2237\n",
      "Fold R2 : 0.7968\n",
      "\n",
      "Fold RMSE : 38.8037\n",
      "Fold MAE : 28.3488\n",
      "Fold R2 : 0.8518\n",
      "\n",
      "Fold RMSE : 47.6693\n",
      "Fold MAE : 29.3928\n",
      "Fold R2 : 0.8394\n",
      "\n",
      "Fold RMSE : 45.4361\n",
      "Fold MAE : 32.5245\n",
      "Fold R2 : 0.8238\n",
      "\n",
      "Fold RMSE : 47.7451\n",
      "Fold MAE : 32.5032\n",
      "Fold R2 : 0.7773\n",
      "\n",
      "平均RMSE : 45.1581\n",
      "平均MAE : 30.9986\n",
      "平均R2 : 0.8178\n"
     ]
    }
   ],
   "source": [
    "# optunaで最適化されたパラメータをセットし、予測\n",
    "model_xgb_op = xgb.XGBRegressor(**study.best_params)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_xgb_op.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)], verbose=0)\n",
    "    y_pred_scaled = model_xgb_op.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}\\n')\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51b8a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgb/y_scaler.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最終モデルの構築\n",
    "model_xgb_final = xgb.XGBRegressor(**study.best_params)\n",
    "\n",
    "# すべての学習データを標準化して、学習させる\n",
    "X_scaler_final = StandardScaler()\n",
    "y_scaler_final = StandardScaler()\n",
    "autoscaled_X = X_scaler_final.fit_transform(X)\n",
    "autoscaled_y = y_scaler_final.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# 学習\n",
    "model_xgb_final = model_xgb_final.fit(autoscaled_X, autoscaled_y.ravel())\n",
    "\n",
    "# ディレクトリ作成（なければ）\n",
    "os.makedirs('models/xgb', exist_ok=True)\n",
    "\n",
    "# モデルとスケーラーの保存（joblib使用）\n",
    "joblib.dump(model_xgb_final, 'models/xgb/model_xgb.pkl')\n",
    "joblib.dump(X_scaler_final, 'models/xgb/X_scaler.pkl')\n",
    "joblib.dump(y_scaler_final, 'models/xgb/y_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c48df5",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "253a6f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 45.1902\n",
      "Fold MAE : 31.6159\n",
      "Fold R2 : 0.8050\n",
      "\n",
      "Fold RMSE : 44.6490\n",
      "Fold MAE : 32.9797\n",
      "Fold R2 : 0.8038\n",
      "\n",
      "Fold RMSE : 52.8957\n",
      "Fold MAE : 34.8776\n",
      "Fold R2 : 0.8022\n",
      "\n",
      "Fold RMSE : 42.6535\n",
      "Fold MAE : 30.5197\n",
      "Fold R2 : 0.8448\n",
      "\n",
      "Fold RMSE : 50.3521\n",
      "Fold MAE : 34.6076\n",
      "Fold R2 : 0.7523\n",
      "\n",
      "平均RMSE : 47.1481\n",
      "平均MAE : 32.9201\n",
      "平均R2 : 0.8016\n"
     ]
    }
   ],
   "source": [
    "# デフォルト\n",
    "model_lgb = lgb.LGBMRegressor(random_state=1234, verbose=-1)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_lgb.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)])\n",
    "    y_pred_scaled = model_lgb.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe7240",
   "metadata": {},
   "source": [
    "### LightGBM+optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "53819364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',  # LightGBMが内部で使う評価指標\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1,\n",
    "        'device' : 'cpu'\n",
    "    }\n",
    "\n",
    "    # モデル定義\n",
    "    model_lgb = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # 分割、CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "    # 評価指標\n",
    "    rmse_scores = []\n",
    "    # mae_scores = []\n",
    "    # r2_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # 訓練と検証に分類\n",
    "        X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 標準化、DataFrameに戻す\n",
    "        X_scaler = StandardScaler()\n",
    "        autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "        autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "        autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "        # 学習\n",
    "        model_lgb.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)])\n",
    "        y_pred_scaled = model_lgb.predict(autoscaled_X_val)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "        # 性能チェック\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        # mae = mean_absolute_error(y_val, y_pred)\n",
    "        # r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # 結果格納\n",
    "        rmse_scores.append(rmse)\n",
    "        # mae_scores.append(mae)\n",
    "        # r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(rmse_scores)  # 最適化したい評価指標を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "385c5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:56:40,392] A new study created in memory with name: regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 21:56:43,114] Trial 0 finished with value: 46.612237582447825 and parameters: {'n_estimators': 228, 'learning_rate': 0.03058956945426088, 'max_depth': 10, 'num_leaves': 57, 'subsample': 0.842476559726396, 'colsample_bytree': 0.9894701869599233, 'reg_alpha': 0.00037161006983939244, 'reg_lambda': 6.925070853712586e-07}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:43,904] Trial 1 finished with value: 70.86689269892109 and parameters: {'n_estimators': 59, 'learning_rate': 0.011879451489631501, 'max_depth': 3, 'num_leaves': 12, 'subsample': 0.9998838520703163, 'colsample_bytree': 0.7427498758995823, 'reg_alpha': 0.0063167522121264875, 'reg_lambda': 9.207357955112185e-05}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:46,125] Trial 2 finished with value: 47.18256426968496 and parameters: {'n_estimators': 186, 'learning_rate': 0.04738067384599583, 'max_depth': 8, 'num_leaves': 62, 'subsample': 0.6504497098052655, 'colsample_bytree': 0.9589293329979198, 'reg_alpha': 0.2548249504922139, 'reg_lambda': 0.02589145904024035}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:47,134] Trial 3 finished with value: 49.615009055332415 and parameters: {'n_estimators': 65, 'learning_rate': 0.033985926203328756, 'max_depth': 9, 'num_leaves': 58, 'subsample': 0.9838821380078162, 'colsample_bytree': 0.9322956764908461, 'reg_alpha': 0.015179099184465616, 'reg_lambda': 0.0006625704279238487}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:48,602] Trial 4 finished with value: 47.63638206073237 and parameters: {'n_estimators': 112, 'learning_rate': 0.04269007330957889, 'max_depth': 9, 'num_leaves': 94, 'subsample': 0.8105247469522907, 'colsample_bytree': 0.8748164870029718, 'reg_alpha': 0.00222187719085597, 'reg_lambda': 0.0002939047485666149}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:50,170] Trial 5 finished with value: 48.09182209092292 and parameters: {'n_estimators': 261, 'learning_rate': 0.12776642590300563, 'max_depth': 3, 'num_leaves': 14, 'subsample': 0.9935646745329643, 'colsample_bytree': 0.593293645440766, 'reg_alpha': 0.01795034600638374, 'reg_lambda': 1.2532160871393797e-07}. Best is trial 0 with value: 46.612237582447825.\n",
      "[I 2025-08-06 21:56:51,518] Trial 6 finished with value: 46.495586325239756 and parameters: {'n_estimators': 252, 'learning_rate': 0.13036154414448498, 'max_depth': 3, 'num_leaves': 10, 'subsample': 0.9433742082769858, 'colsample_bytree': 0.5201088711195114, 'reg_alpha': 2.7437024439832405e-07, 'reg_lambda': 0.015258746738788506}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:56:52,503] Trial 7 finished with value: 48.593642250675565 and parameters: {'n_estimators': 99, 'learning_rate': 0.1461516252203238, 'max_depth': 4, 'num_leaves': 49, 'subsample': 0.8275375644471242, 'colsample_bytree': 0.6494945657103348, 'reg_alpha': 4.48760556589731e-06, 'reg_lambda': 5.623808713842758e-05}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:56:54,026] Trial 8 finished with value: 47.266680528226296 and parameters: {'n_estimators': 161, 'learning_rate': 0.13117572494074958, 'max_depth': 7, 'num_leaves': 51, 'subsample': 0.6941079382937339, 'colsample_bytree': 0.5409977084148692, 'reg_alpha': 6.024859551894757e-07, 'reg_lambda': 4.657132839598216e-07}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:56:56,615] Trial 9 finished with value: 48.43935333696409 and parameters: {'n_estimators': 237, 'learning_rate': 0.08909728762154243, 'max_depth': 9, 'num_leaves': 30, 'subsample': 0.578989602893974, 'colsample_bytree': 0.7794699667109906, 'reg_alpha': 1.575685729947798e-07, 'reg_lambda': 4.878282089731773e-06}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:56:58,757] Trial 10 finished with value: 50.629157743747996 and parameters: {'n_estimators': 293, 'learning_rate': 0.272247200079172, 'max_depth': 5, 'num_leaves': 87, 'subsample': 0.8901546331350844, 'colsample_bytree': 0.5241138458691414, 'reg_alpha': 2.468149072122324e-08, 'reg_lambda': 0.6184560136225503}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:00,742] Trial 11 finished with value: 47.82554566666858 and parameters: {'n_estimators': 212, 'learning_rate': 0.01887557815816077, 'max_depth': 6, 'num_leaves': 74, 'subsample': 0.8931848947117502, 'colsample_bytree': 0.7200449204954955, 'reg_alpha': 2.6440915189443713e-05, 'reg_lambda': 1.8970742933532205e-08}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:03,729] Trial 12 finished with value: 46.87306696239621 and parameters: {'n_estimators': 296, 'learning_rate': 0.024252920522685985, 'max_depth': 10, 'num_leaves': 35, 'subsample': 0.8916048032606324, 'colsample_bytree': 0.8380298997346939, 'reg_alpha': 0.00021413680673212744, 'reg_lambda': 0.007483373617180502}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:05,938] Trial 13 finished with value: 47.74223836476004 and parameters: {'n_estimators': 237, 'learning_rate': 0.07234763379754769, 'max_depth': 6, 'num_leaves': 35, 'subsample': 0.7707789957506632, 'colsample_bytree': 0.6593285833380154, 'reg_alpha': 0.00018784875742144746, 'reg_lambda': 0.5175354754985426}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:07,744] Trial 14 finished with value: 50.041671826620885 and parameters: {'n_estimators': 167, 'learning_rate': 0.20110596524287924, 'max_depth': 5, 'num_leaves': 72, 'subsample': 0.9047769225785638, 'colsample_bytree': 0.8411542852782972, 'reg_alpha': 5.666827584080538e-06, 'reg_lambda': 5.292563044706765e-06}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:10,733] Trial 15 finished with value: 48.0823897498412 and parameters: {'n_estimators': 252, 'learning_rate': 0.06848220458526208, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.7201687211726717, 'colsample_bytree': 0.9980410707949672, 'reg_alpha': 1.0434570743835609e-08, 'reg_lambda': 0.019806273980690705}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:12,727] Trial 16 finished with value: 47.322048961706564 and parameters: {'n_estimators': 211, 'learning_rate': 0.02445859122975083, 'max_depth': 10, 'num_leaves': 47, 'subsample': 0.501497341012414, 'colsample_bytree': 0.6669019288560654, 'reg_alpha': 7.257183328170499e-07, 'reg_lambda': 6.404387990135385e-06}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:14,702] Trial 17 finished with value: 47.45178262866331 and parameters: {'n_estimators': 275, 'learning_rate': 0.015358969210589301, 'max_depth': 4, 'num_leaves': 71, 'subsample': 0.8310647380575783, 'colsample_bytree': 0.5702740738176869, 'reg_alpha': 0.0006945500262574703, 'reg_lambda': 0.00206133662214036}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:16,271] Trial 18 finished with value: 47.78716477380957 and parameters: {'n_estimators': 202, 'learning_rate': 0.09683206852237819, 'max_depth': 8, 'num_leaves': 40, 'subsample': 0.9554746642236043, 'colsample_bytree': 0.8922003147393929, 'reg_alpha': 0.6081263649705019, 'reg_lambda': 0.10788189509522758}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:17,780] Trial 19 finished with value: 47.51138046856901 and parameters: {'n_estimators': 138, 'learning_rate': 0.03271039784460064, 'max_depth': 5, 'num_leaves': 24, 'subsample': 0.9372482304405265, 'colsample_bytree': 0.790904865882998, 'reg_alpha': 1.4634046083344756e-05, 'reg_lambda': 5.94494632379504e-07}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:20,080] Trial 20 finished with value: 48.84238760338228 and parameters: {'n_estimators': 233, 'learning_rate': 0.2765205972538554, 'max_depth': 8, 'num_leaves': 84, 'subsample': 0.7770245155582887, 'colsample_bytree': 0.6129724575375216, 'reg_alpha': 5.42354292110313e-05, 'reg_lambda': 1.2747422267312703e-08}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:23,067] Trial 21 finished with value: 47.35259630563506 and parameters: {'n_estimators': 296, 'learning_rate': 0.023621526419376617, 'max_depth': 10, 'num_leaves': 42, 'subsample': 0.8592116578689826, 'colsample_bytree': 0.8343220224812615, 'reg_alpha': 0.000286596373264981, 'reg_lambda': 0.006629095675067044}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:25,963] Trial 22 finished with value: 48.09261598944103 and parameters: {'n_estimators': 277, 'learning_rate': 0.010278247534408572, 'max_depth': 10, 'num_leaves': 21, 'subsample': 0.9323108514318242, 'colsample_bytree': 0.9959997832319076, 'reg_alpha': 0.000988791745064462, 'reg_lambda': 0.002769381650647528}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:28,897] Trial 23 finished with value: 47.27068680886619 and parameters: {'n_estimators': 262, 'learning_rate': 0.034932186745196776, 'max_depth': 9, 'num_leaves': 33, 'subsample': 0.8720921285083407, 'colsample_bytree': 0.9215493058487245, 'reg_alpha': 9.036782753954811e-05, 'reg_lambda': 0.06102890350050251}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:31,727] Trial 24 finished with value: 47.16274606441435 and parameters: {'n_estimators': 296, 'learning_rate': 0.0242803881609162, 'max_depth': 10, 'num_leaves': 60, 'subsample': 0.8045574917302099, 'colsample_bytree': 0.7193336381498697, 'reg_alpha': 0.07885851477542563, 'reg_lambda': 2.971086046094711e-05}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:34,254] Trial 25 finished with value: 48.27094055665846 and parameters: {'n_estimators': 230, 'learning_rate': 0.061785450952695616, 'max_depth': 8, 'num_leaves': 18, 'subsample': 0.8514479183798358, 'colsample_bytree': 0.8124426331643745, 'reg_alpha': 1.9444713074290175e-06, 'reg_lambda': 0.0007591440626264658}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:36,944] Trial 26 finished with value: 47.05804522931999 and parameters: {'n_estimators': 274, 'learning_rate': 0.014334936591336053, 'max_depth': 4, 'num_leaves': 41, 'subsample': 0.9148806310478239, 'colsample_bytree': 0.8776205994551881, 'reg_alpha': 8.436374459734553e-08, 'reg_lambda': 0.007443615213466504}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:39,365] Trial 27 finished with value: 47.083484520880326 and parameters: {'n_estimators': 196, 'learning_rate': 0.04929863304424291, 'max_depth': 7, 'num_leaves': 10, 'subsample': 0.9540526588796523, 'colsample_bytree': 0.9353378252243472, 'reg_alpha': 0.002869921166689417, 'reg_lambda': 0.26768126867662956}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:41,411] Trial 28 finished with value: 47.739844146426584 and parameters: {'n_estimators': 220, 'learning_rate': 0.020036026068416642, 'max_depth': 9, 'num_leaves': 66, 'subsample': 0.7383880458232932, 'colsample_bytree': 0.6952759353094536, 'reg_alpha': 2.354323254422758e-05, 'reg_lambda': 2.32163560196964e-05}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:43,037] Trial 29 finished with value: 48.328088666972306 and parameters: {'n_estimators': 246, 'learning_rate': 0.18510359335633886, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.8637849033668266, 'colsample_bytree': 0.7565438256314364, 'reg_alpha': 0.0003897889100926544, 'reg_lambda': 0.0001593278683972423}. Best is trial 6 with value: 46.495586325239756.\n",
      "[I 2025-08-06 21:57:46,291] Trial 30 finished with value: 46.43313695934933 and parameters: {'n_estimators': 276, 'learning_rate': 0.028621932227980797, 'max_depth': 10, 'num_leaves': 15, 'subsample': 0.9671983496737804, 'colsample_bytree': 0.9639371768339434, 'reg_alpha': 0.005889790036878261, 'reg_lambda': 6.894491332471126e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:57:49,470] Trial 31 finished with value: 46.85110637144156 and parameters: {'n_estimators': 280, 'learning_rate': 0.030201889445194943, 'max_depth': 10, 'num_leaves': 16, 'subsample': 0.9744504078658652, 'colsample_bytree': 0.961577334680531, 'reg_alpha': 0.009013484265030843, 'reg_lambda': 6.977266224913087e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:57:52,519] Trial 32 finished with value: 46.886514898839174 and parameters: {'n_estimators': 267, 'learning_rate': 0.03978683822122569, 'max_depth': 10, 'num_leaves': 15, 'subsample': 0.9983594478503944, 'colsample_bytree': 0.964879540709648, 'reg_alpha': 0.04320795856263963, 'reg_lambda': 9.07940450173782e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:57:55,760] Trial 33 finished with value: 46.9957235300399 and parameters: {'n_estimators': 282, 'learning_rate': 0.029971235230268314, 'max_depth': 9, 'num_leaves': 10, 'subsample': 0.9655037266168855, 'colsample_bytree': 0.9606846083098096, 'reg_alpha': 0.011126551349318189, 'reg_lambda': 5.727421684624488e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:57:58,671] Trial 34 finished with value: 47.640245787077426 and parameters: {'n_estimators': 250, 'learning_rate': 0.049259073906042075, 'max_depth': 8, 'num_leaves': 20, 'subsample': 0.9667722418925209, 'colsample_bytree': 0.9146623571238894, 'reg_alpha': 0.002460275886056271, 'reg_lambda': 6.724948895034956e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:00,893] Trial 35 finished with value: 46.86194516224926 and parameters: {'n_estimators': 185, 'learning_rate': 0.03960962352092271, 'max_depth': 9, 'num_leaves': 56, 'subsample': 0.9272711635193858, 'colsample_bytree': 0.9680208426022533, 'reg_alpha': 0.12897649879487677, 'reg_lambda': 1.6578940807573099e-06}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:03,825] Trial 36 finished with value: 46.71009657609547 and parameters: {'n_estimators': 258, 'learning_rate': 0.028706612745818982, 'max_depth': 10, 'num_leaves': 16, 'subsample': 0.9974816544222256, 'colsample_bytree': 0.9400927707650115, 'reg_alpha': 0.0043403367393722685, 'reg_lambda': 3.1540926156627775e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:06,566] Trial 37 finished with value: 47.168732075200744 and parameters: {'n_estimators': 257, 'learning_rate': 0.01704258606327261, 'max_depth': 9, 'num_leaves': 22, 'subsample': 0.9920095520484158, 'colsample_bytree': 0.8952565010345412, 'reg_alpha': 0.030742432027669953, 'reg_lambda': 2.11736792406622e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:07,617] Trial 38 finished with value: 66.74341439838152 and parameters: {'n_estimators': 63, 'learning_rate': 0.013125025840215795, 'max_depth': 10, 'num_leaves': 100, 'subsample': 0.675055501432847, 'colsample_bytree': 0.9996786288492635, 'reg_alpha': 0.004286214495815547, 'reg_lambda': 3.051944572211191e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:09,196] Trial 39 finished with value: 46.780853225667116 and parameters: {'n_estimators': 222, 'learning_rate': 0.09023705526802046, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.9412121419320248, 'colsample_bytree': 0.8565228160105601, 'reg_alpha': 0.0010318036619730514, 'reg_lambda': 2.149139451808677e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:10,091] Trial 40 finished with value: 47.390376349188706 and parameters: {'n_estimators': 84, 'learning_rate': 0.05732049980701579, 'max_depth': 8, 'num_leaves': 12, 'subsample': 0.7957587890102865, 'colsample_bytree': 0.5038353688324894, 'reg_alpha': 0.3500454054924258, 'reg_lambda': 1.6974126086053472e-06}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:11,832] Trial 41 finished with value: 48.22170647194569 and parameters: {'n_estimators': 225, 'learning_rate': 0.10652413226220125, 'max_depth': 3, 'num_leaves': 28, 'subsample': 0.9405975852501396, 'colsample_bytree': 0.9356057490023667, 'reg_alpha': 0.0010088263144353337, 'reg_lambda': 2.1147092686403562e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:13,991] Trial 42 finished with value: 47.800598357373914 and parameters: {'n_estimators': 244, 'learning_rate': 0.08313999001760775, 'max_depth': 4, 'num_leaves': 16, 'subsample': 0.9158787905162143, 'colsample_bytree': 0.8656299040323732, 'reg_alpha': 0.006168900361978317, 'reg_lambda': 3.330043403121184e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:15,595] Trial 43 finished with value: 48.057736529014974 and parameters: {'n_estimators': 208, 'learning_rate': 0.11521658679285922, 'max_depth': 3, 'num_leaves': 53, 'subsample': 0.9745037519296423, 'colsample_bytree': 0.9094370388985563, 'reg_alpha': 0.0011564916907693989, 'reg_lambda': 2.1981569519827339e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:16,951] Trial 44 finished with value: 48.186800783255066 and parameters: {'n_estimators': 143, 'learning_rate': 0.14861647959935012, 'max_depth': 3, 'num_leaves': 24, 'subsample': 0.8821183544553093, 'colsample_bytree': 0.9429322467001305, 'reg_alpha': 0.00010653079782624735, 'reg_lambda': 1.5475541933872776e-06}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:19,138] Trial 45 finished with value: 46.503869659365876 and parameters: {'n_estimators': 224, 'learning_rate': 0.07917372030853922, 'max_depth': 4, 'num_leaves': 13, 'subsample': 0.999545504519796, 'colsample_bytree': 0.9758278266634611, 'reg_alpha': 0.020889062876273595, 'reg_lambda': 1.2101766657637027e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:21,418] Trial 46 finished with value: 47.13129865059899 and parameters: {'n_estimators': 240, 'learning_rate': 0.07570973353885206, 'max_depth': 4, 'num_leaves': 14, 'subsample': 0.9940714084966061, 'colsample_bytree': 0.976925807369524, 'reg_alpha': 0.14260321569100312, 'reg_lambda': 1.522803271545403e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:23,915] Trial 47 finished with value: 48.5745462500875 and parameters: {'n_estimators': 259, 'learning_rate': 0.17029576886742417, 'max_depth': 5, 'num_leaves': 65, 'subsample': 0.8373549768806993, 'colsample_bytree': 0.9471245426799013, 'reg_alpha': 0.025161778773826117, 'reg_lambda': 3.411558781038503e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:26,592] Trial 48 finished with value: 46.89928888383061 and parameters: {'n_estimators': 287, 'learning_rate': 0.027906720155468606, 'max_depth': 4, 'num_leaves': 10, 'subsample': 0.9997192516631694, 'colsample_bytree': 0.90497105190111, 'reg_alpha': 0.011195623852635722, 'reg_lambda': 7.992653018366008e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:29,490] Trial 49 finished with value: 46.65591738527824 and parameters: {'n_estimators': 264, 'learning_rate': 0.021041866959932563, 'max_depth': 6, 'num_leaves': 19, 'subsample': 0.958811637201815, 'colsample_bytree': 0.981831212662934, 'reg_alpha': 0.06273130779002785, 'reg_lambda': 1.162883755882816e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:31,251] Trial 50 finished with value: 47.65663091100178 and parameters: {'n_estimators': 194, 'learning_rate': 0.022064198760682524, 'max_depth': 6, 'num_leaves': 46, 'subsample': 0.9038352380877055, 'colsample_bytree': 0.6327242099810692, 'reg_alpha': 1.544934663287395e-07, 'reg_lambda': 4.4997968092758426e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:34,321] Trial 51 finished with value: 46.89150447373191 and parameters: {'n_estimators': 265, 'learning_rate': 0.018524880312320084, 'max_depth': 7, 'num_leaves': 18, 'subsample': 0.952660255865634, 'colsample_bytree': 0.9804900196831863, 'reg_alpha': 0.0535564720973522, 'reg_lambda': 1.201114894628949e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:35,942] Trial 52 finished with value: 46.91203227912213 and parameters: {'n_estimators': 251, 'learning_rate': 0.035283092254835544, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.9774583707822533, 'colsample_bytree': 0.5689267200536163, 'reg_alpha': 0.9851554780871248, 'reg_lambda': 2.856208327442692e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:38,662] Trial 53 finished with value: 46.77319098694767 and parameters: {'n_estimators': 238, 'learning_rate': 0.026536370973945046, 'max_depth': 5, 'num_leaves': 19, 'subsample': 0.5867334142636941, 'colsample_bytree': 0.9829166953171501, 'reg_alpha': 0.004282326772130752, 'reg_lambda': 5.066854468641667e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:41,809] Trial 54 finished with value: 46.9866239064115 and parameters: {'n_estimators': 270, 'learning_rate': 0.04200607628460829, 'max_depth': 9, 'num_leaves': 77, 'subsample': 0.9552079141018774, 'colsample_bytree': 0.9504606675575482, 'reg_alpha': 0.01912525601672881, 'reg_lambda': 1.855834273912039e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:44,732] Trial 55 finished with value: 47.236416769141485 and parameters: {'n_estimators': 287, 'learning_rate': 0.01662444778263847, 'max_depth': 6, 'num_leaves': 32, 'subsample': 0.9737140122310034, 'colsample_bytree': 0.9239063917333539, 'reg_alpha': 0.14967388257314307, 'reg_lambda': 1.136482067647651e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:47,277] Trial 56 finished with value: 46.773888788538954 and parameters: {'n_estimators': 219, 'learning_rate': 0.02172633111738572, 'max_depth': 10, 'num_leaves': 25, 'subsample': 0.89554585119432, 'colsample_bytree': 0.9824937312976402, 'reg_alpha': 0.0004746599927945784, 'reg_lambda': 1.0434745005770037e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:49,643] Trial 57 finished with value: 48.2783512880626 and parameters: {'n_estimators': 232, 'learning_rate': 0.13025328421996293, 'max_depth': 5, 'num_leaves': 36, 'subsample': 0.9159642360624105, 'colsample_bytree': 0.883926502225904, 'reg_alpha': 0.0020268201607184233, 'reg_lambda': 4.2323072758367775e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:51,954] Trial 58 finished with value: 48.78111227270654 and parameters: {'n_estimators': 300, 'learning_rate': 0.23570252906614883, 'max_depth': 7, 'num_leaves': 13, 'subsample': 0.9250216909928473, 'colsample_bytree': 0.9874186550729391, 'reg_alpha': 0.0629446895348259, 'reg_lambda': 0.00035035143822400596}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:53,745] Trial 59 finished with value: 47.04003756418591 and parameters: {'n_estimators': 184, 'learning_rate': 0.06185375997801337, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.9464347709477651, 'colsample_bytree': 0.9487571373288382, 'reg_alpha': 6.453716843375567e-06, 'reg_lambda': 2.0359091688612888e-08}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:56,529] Trial 60 finished with value: 47.59019942960545 and parameters: {'n_estimators': 260, 'learning_rate': 0.034806164170061285, 'max_depth': 10, 'num_leaves': 17, 'subsample': 0.8781277258075264, 'colsample_bytree': 0.8049515176275732, 'reg_alpha': 5.934219387303661e-07, 'reg_lambda': 1.391435571825502e-07}. Best is trial 30 with value: 46.43313695934933.\n",
      "[I 2025-08-06 21:58:59,032] Trial 61 finished with value: 46.42547449291525 and parameters: {'n_estimators': 236, 'learning_rate': 0.029310477700067696, 'max_depth': 5, 'num_leaves': 19, 'subsample': 0.7154586014188334, 'colsample_bytree': 0.9997328549232114, 'reg_alpha': 0.004394804318159242, 'reg_lambda': 4.789011902383014e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:01,718] Trial 62 finished with value: 46.56772123276288 and parameters: {'n_estimators': 251, 'learning_rate': 0.029150844598780656, 'max_depth': 5, 'num_leaves': 20, 'subsample': 0.7050738940648842, 'colsample_bytree': 0.995756956807883, 'reg_alpha': 0.017859289843268705, 'reg_lambda': 3.949957311651522e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:04,331] Trial 63 finished with value: 46.8327823847087 and parameters: {'n_estimators': 243, 'learning_rate': 0.045740335416815193, 'max_depth': 5, 'num_leaves': 26, 'subsample': 0.7085676575745788, 'colsample_bytree': 0.9743620291318972, 'reg_alpha': 0.016912578918150876, 'reg_lambda': 3.4231161489064557e-06}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:06,820] Trial 64 finished with value: 47.104187495845444 and parameters: {'n_estimators': 207, 'learning_rate': 0.02574229198276442, 'max_depth': 5, 'num_leaves': 21, 'subsample': 0.659014665056084, 'colsample_bytree': 0.9977243528276845, 'reg_alpha': 0.22402341213089638, 'reg_lambda': 0.023272230565691047}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:09,348] Trial 65 finished with value: 46.61308994922736 and parameters: {'n_estimators': 231, 'learning_rate': 0.02070852627893928, 'max_depth': 6, 'num_leaves': 12, 'subsample': 0.7444105982490031, 'colsample_bytree': 0.966845527061757, 'reg_alpha': 0.007456046249548511, 'reg_lambda': 9.874482463683537e-06}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:11,581] Trial 66 finished with value: 46.68440829279936 and parameters: {'n_estimators': 234, 'learning_rate': 0.03722682554473291, 'max_depth': 4, 'num_leaves': 12, 'subsample': 0.7467263003516292, 'colsample_bytree': 0.9621567684177618, 'reg_alpha': 0.002001139502575854, 'reg_lambda': 1.724458519729171e-05}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:12,395] Trial 67 finished with value: 54.31799103369275 and parameters: {'n_estimators': 52, 'learning_rate': 0.0315113307066745, 'max_depth': 6, 'num_leaves': 11, 'subsample': 0.7681199961544318, 'colsample_bytree': 0.7521715941260259, 'reg_alpha': 0.007038211464588073, 'reg_lambda': 0.955576353452828}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:14,139] Trial 68 finished with value: 47.190931662355915 and parameters: {'n_estimators': 214, 'learning_rate': 0.053535914982621176, 'max_depth': 4, 'num_leaves': 57, 'subsample': 0.7291268798554701, 'colsample_bytree': 0.6839311942722384, 'reg_alpha': 0.00023000228082935102, 'reg_lambda': 1.1950087028131142e-06}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:16,584] Trial 69 finished with value: 48.63783165331614 and parameters: {'n_estimators': 227, 'learning_rate': 0.011548879011954767, 'max_depth': 5, 'num_leaves': 61, 'subsample': 0.7004633395469079, 'colsample_bytree': 0.9295239469215468, 'reg_alpha': 5.1808789903603426e-05, 'reg_lambda': 1.0873494560749842e-05}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:18,640] Trial 70 finished with value: 46.943364947769524 and parameters: {'n_estimators': 175, 'learning_rate': 0.023596618813392735, 'max_depth': 5, 'num_leaves': 49, 'subsample': 0.6348232908967677, 'colsample_bytree': 0.9989509634066835, 'reg_alpha': 0.03118752530204242, 'reg_lambda': 4.841415390901325e-05}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:21,396] Trial 71 finished with value: 46.9747920679064 and parameters: {'n_estimators': 253, 'learning_rate': 0.020029636863801582, 'max_depth': 6, 'num_leaves': 19, 'subsample': 0.7629330165851833, 'colsample_bytree': 0.9687700569791524, 'reg_alpha': 0.09401743586449017, 'reg_lambda': 9.669633512696159e-05}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:24,371] Trial 72 finished with value: 46.54893625104573 and parameters: {'n_estimators': 273, 'learning_rate': 0.021703349152421635, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.6880837413813982, 'colsample_bytree': 0.9571274044302243, 'reg_alpha': 1.3977732654102435e-08, 'reg_lambda': 4.818473300289027e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:27,367] Trial 73 finished with value: 46.55914489646475 and parameters: {'n_estimators': 272, 'learning_rate': 0.01787597220269246, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.6859795230994236, 'colsample_bytree': 0.9555453885125144, 'reg_alpha': 3.694781407410199e-08, 'reg_lambda': 4.9442932334826704e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:30,258] Trial 74 finished with value: 46.646737821252735 and parameters: {'n_estimators': 271, 'learning_rate': 0.017454023403372907, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.6720942665563023, 'colsample_bytree': 0.9542400700870397, 'reg_alpha': 1.3390144192010278e-08, 'reg_lambda': 5.2453399586706183e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:33,189] Trial 75 finished with value: 46.868022390887376 and parameters: {'n_estimators': 288, 'learning_rate': 0.013333415708253133, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.6321857732788319, 'colsample_bytree': 0.9222658271178639, 'reg_alpha': 4.588058758831968e-08, 'reg_lambda': 1.350034625956551e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:34,976] Trial 76 finished with value: 47.13118460538206 and parameters: {'n_estimators': 280, 'learning_rate': 0.015472788821290993, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.6778935700024886, 'colsample_bytree': 0.5669255975844889, 'reg_alpha': 2.6215659012900595e-08, 'reg_lambda': 3.42087953584438e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:37,271] Trial 77 finished with value: 47.83188334580299 and parameters: {'n_estimators': 248, 'learning_rate': 0.031377517282748, 'max_depth': 4, 'num_leaves': 14, 'subsample': 0.7160253489883563, 'colsample_bytree': 0.7704840612192809, 'reg_alpha': 5.196312147434439e-08, 'reg_lambda': 8.076234839322406e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:40,262] Trial 78 finished with value: 46.62279131642488 and parameters: {'n_estimators': 272, 'learning_rate': 0.026079914082187863, 'max_depth': 6, 'num_leaves': 64, 'subsample': 0.6844856667991164, 'colsample_bytree': 0.8959660003326602, 'reg_alpha': 2.194099960913406e-08, 'reg_lambda': 4.8443527843794825e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:42,404] Trial 79 finished with value: 47.61681700802635 and parameters: {'n_estimators': 253, 'learning_rate': 0.018775235520301446, 'max_depth': 7, 'num_leaves': 38, 'subsample': 0.6411627639930967, 'colsample_bytree': 0.5910373796145616, 'reg_alpha': 3.182723042707652e-07, 'reg_lambda': 2.0571395231443487e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:44,914] Trial 80 finished with value: 48.76876190269642 and parameters: {'n_estimators': 280, 'learning_rate': 0.14916754508338892, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.7934336941960679, 'colsample_bytree': 0.9895148568222588, 'reg_alpha': 1.1390752072485097e-07, 'reg_lambda': 0.0025687993798950946}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:47,634] Trial 81 finished with value: 46.628322126266355 and parameters: {'n_estimators': 240, 'learning_rate': 0.02377654498464338, 'max_depth': 6, 'num_leaves': 16, 'subsample': 0.7348369966906346, 'colsample_bytree': 0.9636443821126505, 'reg_alpha': 1.2069908970608667e-08, 'reg_lambda': 0.0011836839262061223}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:50,176] Trial 82 finished with value: 46.98258507479878 and parameters: {'n_estimators': 231, 'learning_rate': 0.02730833913405651, 'max_depth': 6, 'num_leaves': 21, 'subsample': 0.6982059100879849, 'colsample_bytree': 0.9362145175279994, 'reg_alpha': 2.6186153721574856e-07, 'reg_lambda': 3.998127268199435e-06}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:52,869] Trial 83 finished with value: 46.53853642029931 and parameters: {'n_estimators': 246, 'learning_rate': 0.022523445143247296, 'max_depth': 6, 'num_leaves': 10, 'subsample': 0.7569091008045323, 'colsample_bytree': 0.9718362604898286, 'reg_alpha': 2.3510736273702465e-06, 'reg_lambda': 1.3889016960952538e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:54,903] Trial 84 finished with value: 47.14540007024111 and parameters: {'n_estimators': 218, 'learning_rate': 0.029774642314796148, 'max_depth': 5, 'num_leaves': 10, 'subsample': 0.6134345276597764, 'colsample_bytree': 0.7370056194070098, 'reg_alpha': 4.15013710554466e-06, 'reg_lambda': 1.4058160721855886e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 21:59:57,630] Trial 85 finished with value: 47.66097068193905 and parameters: {'n_estimators': 266, 'learning_rate': 0.10845759144401212, 'max_depth': 5, 'num_leaves': 17, 'subsample': 0.7225640771312969, 'colsample_bytree': 0.9528674294905148, 'reg_alpha': 4.929772179311388e-08, 'reg_lambda': 0.04747377998862076}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:00,304] Trial 86 finished with value: 46.551019766712145 and parameters: {'n_estimators': 255, 'learning_rate': 0.022439053657297533, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.8174190987604106, 'colsample_bytree': 0.9134065083029378, 'reg_alpha': 1.4226970296541433e-06, 'reg_lambda': 7.743681945829652e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:02,929] Trial 87 finished with value: 47.0983985685459 and parameters: {'n_estimators': 258, 'learning_rate': 0.01586177873354216, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.820477409659345, 'colsample_bytree': 0.9116674214887215, 'reg_alpha': 8.8485117866864e-07, 'reg_lambda': 7.583116580219513e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:06,128] Trial 88 finished with value: 46.57223344505424 and parameters: {'n_estimators': 290, 'learning_rate': 0.022951670959190283, 'max_depth': 7, 'num_leaves': 20, 'subsample': 0.7568239440119867, 'colsample_bytree': 0.9724849294935968, 'reg_alpha': 1.3017682720462284e-06, 'reg_lambda': 2.9084232124458916e-07}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:08,805] Trial 89 finished with value: 46.52398178355161 and parameters: {'n_estimators': 246, 'learning_rate': 0.02013825067973561, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.6602273781650194, 'colsample_bytree': 0.9403274484239386, 'reg_alpha': 3.1136678640828752e-06, 'reg_lambda': 3.7420660021341305e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:11,244] Trial 90 finished with value: 47.064306009666105 and parameters: {'n_estimators': 245, 'learning_rate': 0.018189859987778886, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.6609567772032358, 'colsample_bytree': 0.8472190750778809, 'reg_alpha': 1.7960304705859971e-06, 'reg_lambda': 2.340903332353243e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:14,058] Trial 91 finished with value: 46.991890213785226 and parameters: {'n_estimators': 275, 'learning_rate': 0.014224307875505276, 'max_depth': 6, 'num_leaves': 16, 'subsample': 0.7843461487307005, 'colsample_bytree': 0.9353647002340463, 'reg_alpha': 5.306363216080713e-06, 'reg_lambda': 3.9269347087447536e-08}. Best is trial 61 with value: 46.42547449291525.\n",
      "[I 2025-08-06 22:00:16,881] Trial 92 finished with value: 46.3403279738494 and parameters: {'n_estimators': 255, 'learning_rate': 0.01988402943452076, 'max_depth': 6, 'num_leaves': 25, 'subsample': 0.6936459178623545, 'colsample_bytree': 0.9451153576709722, 'reg_alpha': 2.890962152474971e-07, 'reg_lambda': 7.921445115940868e-08}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:19,671] Trial 93 finished with value: 46.843814279343775 and parameters: {'n_estimators': 263, 'learning_rate': 0.02036892064772775, 'max_depth': 6, 'num_leaves': 24, 'subsample': 0.6887178352886439, 'colsample_bytree': 0.9213881062386612, 'reg_alpha': 3.8532961090246224e-07, 'reg_lambda': 9.120464945121044e-08}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:22,446] Trial 94 finished with value: 46.38814799767674 and parameters: {'n_estimators': 254, 'learning_rate': 0.0196363974023804, 'max_depth': 7, 'num_leaves': 30, 'subsample': 0.6179480962250157, 'colsample_bytree': 0.9543920359471083, 'reg_alpha': 6.078382644133124e-07, 'reg_lambda': 1.6611386198018957e-07}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:25,127] Trial 95 finished with value: 46.60497902291213 and parameters: {'n_estimators': 255, 'learning_rate': 0.019690184397272957, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.61757024676644, 'colsample_bytree': 0.905166359542655, 'reg_alpha': 3.2960076778216144e-06, 'reg_lambda': 1.8421173469345287e-07}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:27,837] Trial 96 finished with value: 46.55428272711733 and parameters: {'n_estimators': 239, 'learning_rate': 0.024034115932959288, 'max_depth': 7, 'num_leaves': 18, 'subsample': 0.5335757538182966, 'colsample_bytree': 0.9438698947815153, 'reg_alpha': 2.3205119429075574e-07, 'reg_lambda': 1.0321473022096574e-08}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:29,628] Trial 97 finished with value: 46.44849778986776 and parameters: {'n_estimators': 225, 'learning_rate': 0.021506542015127535, 'max_depth': 3, 'num_leaves': 12, 'subsample': 0.6077105668604176, 'colsample_bytree': 0.9303312139906914, 'reg_alpha': 4.867522395762216e-07, 'reg_lambda': 7.837187656612021e-08}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:31,404] Trial 98 finished with value: 46.36153226984462 and parameters: {'n_estimators': 227, 'learning_rate': 0.02566166878559347, 'max_depth': 3, 'num_leaves': 26, 'subsample': 0.5904762143372019, 'colsample_bytree': 0.8850271647152026, 'reg_alpha': 1.0816587550906729e-05, 'reg_lambda': 0.22255211239829992}. Best is trial 92 with value: 46.3403279738494.\n",
      "[I 2025-08-06 22:00:33,097] Trial 99 finished with value: 46.93706106247167 and parameters: {'n_estimators': 223, 'learning_rate': 0.06900051086569654, 'max_depth': 3, 'num_leaves': 12, 'subsample': 0.5842619426508625, 'colsample_bytree': 0.887970147745586, 'reg_alpha': 8.891186210269382e-06, 'reg_lambda': 0.10464248531583185}. Best is trial 92 with value: 46.3403279738494.\n"
     ]
    }
   ],
   "source": [
    "# 最適化\n",
    "study = optuna.create_study(direction='minimize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f60d9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  RMSE: 46.3403\n",
      "  Params:\n",
      "    n_estimators: 255\n",
      "    learning_rate: 0.01988402943452076\n",
      "    max_depth: 6\n",
      "    num_leaves: 25\n",
      "    subsample: 0.6936459178623545\n",
      "    colsample_bytree: 0.9451153576709722\n",
      "    reg_alpha: 2.890962152474971e-07\n",
      "    reg_lambda: 7.921445115940868e-08\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ・スコアの確認\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  RMSE: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cab2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 46.5304\n",
      "Fold MAE : 31.9990\n",
      "Fold R2 : 0.7933\n",
      "\n",
      "Fold RMSE : 44.0963\n",
      "Fold MAE : 32.5853\n",
      "Fold R2 : 0.8086\n",
      "\n",
      "Fold RMSE : 50.2665\n",
      "Fold MAE : 32.5033\n",
      "Fold R2 : 0.8214\n",
      "\n",
      "Fold RMSE : 44.5412\n",
      "Fold MAE : 32.0285\n",
      "Fold R2 : 0.8307\n",
      "\n",
      "Fold RMSE : 48.8479\n",
      "Fold MAE : 33.3066\n",
      "Fold R2 : 0.7669\n",
      "\n",
      "平均RMSE : 46.8565\n",
      "平均MAE : 32.4846\n",
      "平均R2 : 0.8042\n"
     ]
    }
   ],
   "source": [
    "# optunaで最適化されたパラメータをセットし、予測\n",
    "model_lgb_op = lgb.LGBMRegressor(**study.best_params)\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# スコア保存用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 訓練と検証に分類\n",
    "    X_train, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # 標準化、DataFrameに戻す\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    autoscaled_X_val = pd.DataFrame(X_scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1,1)), index=y_train.index, columns=['y'])\n",
    "    autoscaled_y_val = pd.DataFrame(y_scaler.transform(y_val.values.reshape(-1,1)), index=y_val.index, columns=['y'])\n",
    "\n",
    "    # 学習\n",
    "    model_lgb_op.fit(autoscaled_X_train, autoscaled_y_train, eval_set=[(autoscaled_X_val, autoscaled_y_val)])\n",
    "    y_pred_scaled = model_lgb_op.predict(autoscaled_X_val)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # 性能チェック\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2 : {r2:.4f}')\n",
    "    print()\n",
    "\n",
    "print(f'平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2 : {np.mean(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2dcd2406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lgb/y_scaler.pkl']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最終モデルの構築\n",
    "model_lgb_final = lgb.LGBMRegressor(**study.best_params)\n",
    "\n",
    "# すべての学習データを標準化して、学習させる\n",
    "X_scaler_final = StandardScaler()\n",
    "y_scaler_final = StandardScaler()\n",
    "autoscaled_X = X_scaler_final.fit_transform(X)\n",
    "autoscaled_y = y_scaler_final.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# 学習\n",
    "model_lgb_final = model_lgb_final.fit(autoscaled_X, autoscaled_y.ravel())\n",
    "\n",
    "# ディレクトリ作成（なければ）\n",
    "os.makedirs('models/lgb', exist_ok=True)\n",
    "\n",
    "# モデルとスケーラーの保存\n",
    "joblib.dump(model_lgb_final, 'models/lgb/model_lgb.pkl')\n",
    "joblib.dump(X_scaler_final, 'models/lgb/X_scaler.pkl')\n",
    "joblib.dump(y_scaler_final, 'models/lgb/y_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10597f",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da33a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fc53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN定義\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee6a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習loop\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # 勾配クリッピング追加！\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 評価\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            pred = model(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a7c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 49.5397\n",
      "Fold MAE : 34.3333\n",
      "Fold R2  : 0.7657\n",
      "\n",
      "Fold RMSE : 45.5003\n",
      "Fold MAE : 34.3626\n",
      "Fold R2  : 0.7963\n",
      "\n",
      "Fold RMSE : 62.7420\n",
      "Fold MAE : 38.1763\n",
      "Fold R2  : 0.7217\n",
      "\n",
      "Fold RMSE : 48.0101\n",
      "Fold MAE : 35.1398\n",
      "Fold R2  : 0.8033\n",
      "\n",
      "Fold RMSE : 50.9370\n",
      "Fold MAE : 36.0248\n",
      "Fold R2  : 0.7466\n",
      "\n",
      "平均RMSE: 51.3458 ± 5.9766\n",
      "平均MAE: 35.6074 ± 1.4258\n",
      "平均R2: 0.7667 ± 0.0305\n"
     ]
    }
   ],
   "source": [
    "# 評価指標格納用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # モデル構築\n",
    "    model_nn = MLPRegressor(input_dim=X.shape[1]).to(device)\n",
    "    # 損失関数\n",
    "    criterion = nn.MSELoss()\n",
    "    # 最適化関数\n",
    "    optimizer = torch.optim.Adam(model_nn.parameters(), lr=1e-4)\n",
    "\n",
    "    # 分割\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_val = X.iloc[val_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_val = y.iloc[val_index]\n",
    "\n",
    "    # 標準化（情報漏洩防止）\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = X_scaler.fit_transform(X_train)\n",
    "    autoscaled_X_val = X_scaler.transform(X_val)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    autoscaled_y_val = y_scaler.transform(y_val.values.reshape(-1, 1))\n",
    "\n",
    "    # tensor化\n",
    "    X_train_tensor = torch.tensor(autoscaled_X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(autoscaled_y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    X_val_tensor = torch.tensor(autoscaled_X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(autoscaled_y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # DataLoader\n",
    "    train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "    # 学習ループ\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model_nn, train_dl, optimizer, criterion, device)\n",
    "\n",
    "    # 推論と逆変換\n",
    "    model_nn.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_dl:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_std = model_nn(X_batch).cpu().numpy()\n",
    "            preds.append(y_pred_std)\n",
    "\n",
    "    y_pred = y_scaler.inverse_transform(np.vstack(preds))\n",
    "    y_true = y_scaler.inverse_transform(autoscaled_y_val)\n",
    "\n",
    "    # 評価指標\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2  : {r2:.4f}\\n')\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# 結果出力\n",
    "print(f'平均RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}')\n",
    "print(f'平均MAE: {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}')\n",
    "print(f'平均R2: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33228af1",
   "metadata": {},
   "source": [
    "### NN+Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0a988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b02816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット定義\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "# 学習loop\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 評価\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            pred = model(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30535a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna設定\n",
    "def define_model(trial, input_dim):\n",
    "    layers = []\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 1024)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    activation_name = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"])\n",
    "    use_batchnorm = trial.suggest_categorical(\"use_batchnorm\", [True, False])\n",
    "\n",
    "    in_dim = input_dim\n",
    "    for i in range(n_layers):\n",
    "        layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "\n",
    "        # 活性化関数の前に入れる\n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        if activation_name == \"relu\":\n",
    "            layers.append(nn.ReLU())\n",
    "        else:\n",
    "            layers.append(nn.LeakyReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        in_dim = hidden_dim\n",
    "\n",
    "    layers.append(nn.Linear(in_dim, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータ提案\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    epochs = trial.suggest_int(\"epochs\", 30, 100)\n",
    "\n",
    "    # モデル定義\n",
    "    model = define_model(trial, X.shape[1]).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    val_losses = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # 標準化\n",
    "        X_scaler = StandardScaler()\n",
    "        autoscaled_X_train = X_scaler.fit_transform(X_train)\n",
    "        autoscaled_X_val = X_scaler.transform(X_val)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        autoscaled_y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "        autoscaled_y_val = y_scaler.transform(y_val.values.reshape(-1, 1))\n",
    "\n",
    "        # Dataset, DataLoader\n",
    "        train_ds = RegressionDataset(autoscaled_X_train, autoscaled_y_train)\n",
    "        val_ds = RegressionDataset(autoscaled_X_val, autoscaled_y_val)\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # 学習、評価\n",
    "        for epoch in range(epochs):\n",
    "            train(model, train_dl, optimizer, criterion, device)\n",
    "\n",
    "        val_loss = evaluate(model, val_dl, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return np.mean(val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6ecbb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 19:38:10,997] A new study created in memory with name: no-name-d847193f-a611-4640-82b9-cdcc5e82b15b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna最適化開始...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 19:38:14,930] Trial 0 finished with value: 0.3031741701066494 and parameters: {'batch_size': 64, 'lr': 0.00030933837402161407, 'optimizer': 'SGD', 'epochs': 38, 'n_layers': 2, 'hidden_dim': 434, 'dropout_rate': 0.05071778690889278, 'activation': 'leaky_relu', 'use_batchnorm': True}. Best is trial 0 with value: 0.3031741701066494.\n",
      "[I 2025-08-17 19:38:20,461] Trial 1 finished with value: 0.11292753592133523 and parameters: {'batch_size': 128, 'lr': 0.00023927648110724282, 'optimizer': 'Adam', 'epochs': 75, 'n_layers': 3, 'hidden_dim': 410, 'dropout_rate': 0.4911731660684614, 'activation': 'relu', 'use_batchnorm': True}. Best is trial 1 with value: 0.11292753592133523.\n",
      "[I 2025-08-17 19:38:27,047] Trial 2 finished with value: 0.1687363401055336 and parameters: {'batch_size': 128, 'lr': 0.0005597200372000181, 'optimizer': 'SGD', 'epochs': 58, 'n_layers': 5, 'hidden_dim': 705, 'dropout_rate': 0.23515154090165558, 'activation': 'relu', 'use_batchnorm': True}. Best is trial 1 with value: 0.11292753592133523.\n",
      "[I 2025-08-17 19:38:45,218] Trial 3 finished with value: 1.3489201113581657 and parameters: {'batch_size': 16, 'lr': 5.2620428927825144e-05, 'optimizer': 'SGD', 'epochs': 58, 'n_layers': 4, 'hidden_dim': 683, 'dropout_rate': 0.07122849218573862, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 1 with value: 0.11292753592133523.\n",
      "[I 2025-08-17 19:38:52,217] Trial 4 finished with value: 0.873331606388092 and parameters: {'batch_size': 64, 'lr': 7.811016150469239e-05, 'optimizer': 'SGD', 'epochs': 79, 'n_layers': 3, 'hidden_dim': 799, 'dropout_rate': 0.09601591865183895, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 1 with value: 0.11292753592133523.\n",
      "[I 2025-08-17 19:38:57,838] Trial 5 finished with value: 0.12254616115242242 and parameters: {'batch_size': 32, 'lr': 9.959719335645106e-05, 'optimizer': 'Adam', 'epochs': 33, 'n_layers': 2, 'hidden_dim': 604, 'dropout_rate': 0.03835227816363829, 'activation': 'relu', 'use_batchnorm': True}. Best is trial 1 with value: 0.11292753592133523.\n",
      "[I 2025-08-17 19:39:10,208] Trial 6 finished with value: 0.10181899014860392 and parameters: {'batch_size': 16, 'lr': 3.062705694409806e-05, 'optimizer': 'Adam', 'epochs': 44, 'n_layers': 3, 'hidden_dim': 352, 'dropout_rate': 0.2049095959317121, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 6 with value: 0.10181899014860392.\n",
      "[I 2025-08-17 19:39:35,393] Trial 7 finished with value: 1.426057757437229 and parameters: {'batch_size': 16, 'lr': 1.0323699266471686e-05, 'optimizer': 'SGD', 'epochs': 76, 'n_layers': 5, 'hidden_dim': 250, 'dropout_rate': 0.21175770412270745, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 6 with value: 0.10181899014860392.\n",
      "[I 2025-08-17 19:40:04,101] Trial 8 finished with value: 0.1184564265422523 and parameters: {'batch_size': 16, 'lr': 8.021946472006973e-05, 'optimizer': 'Adam', 'epochs': 82, 'n_layers': 5, 'hidden_dim': 675, 'dropout_rate': 0.32464458789943634, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 6 with value: 0.10181899014860392.\n",
      "[I 2025-08-17 19:40:12,271] Trial 9 finished with value: 0.24043962843716143 and parameters: {'batch_size': 16, 'lr': 0.0006788020120396821, 'optimizer': 'SGD', 'epochs': 39, 'n_layers': 2, 'hidden_dim': 101, 'dropout_rate': 0.22335803950245814, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 6 with value: 0.10181899014860392.\n",
      "[I 2025-08-17 19:40:29,483] Trial 10 finished with value: 0.09929805751889945 and parameters: {'batch_size': 32, 'lr': 1.8680975845373553e-05, 'optimizer': 'Adam', 'epochs': 96, 'n_layers': 4, 'hidden_dim': 1008, 'dropout_rate': 0.3818331050250343, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 10 with value: 0.09929805751889945.\n",
      "[I 2025-08-17 19:40:47,030] Trial 11 finished with value: 0.11357608903199434 and parameters: {'batch_size': 32, 'lr': 1.829678699649673e-05, 'optimizer': 'Adam', 'epochs': 95, 'n_layers': 4, 'hidden_dim': 1014, 'dropout_rate': 0.37185756852407936, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 10 with value: 0.09929805751889945.\n",
      "[I 2025-08-17 19:40:54,550] Trial 12 finished with value: 0.11824675649404526 and parameters: {'batch_size': 32, 'lr': 3.065078100911569e-05, 'optimizer': 'Adam', 'epochs': 49, 'n_layers': 3, 'hidden_dim': 891, 'dropout_rate': 0.4085995021641796, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 10 with value: 0.09929805751889945.\n",
      "[I 2025-08-17 19:41:11,691] Trial 13 finished with value: 0.08404381787404418 and parameters: {'batch_size': 32, 'lr': 2.737611418665898e-05, 'optimizer': 'Adam', 'epochs': 99, 'n_layers': 4, 'hidden_dim': 315, 'dropout_rate': 0.15840215613621586, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 13 with value: 0.08404381787404418.\n",
      "[I 2025-08-17 19:41:27,420] Trial 14 finished with value: 0.20231252163648605 and parameters: {'batch_size': 32, 'lr': 1.0783463685910335e-05, 'optimizer': 'Adam', 'epochs': 100, 'n_layers': 4, 'hidden_dim': 69, 'dropout_rate': 0.125414632671655, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 13 with value: 0.08404381787404418.\n",
      "[I 2025-08-17 19:41:45,473] Trial 15 finished with value: 0.1071851097047329 and parameters: {'batch_size': 32, 'lr': 2.623013307617617e-05, 'optimizer': 'Adam', 'epochs': 89, 'n_layers': 4, 'hidden_dim': 258, 'dropout_rate': 0.3001337755217378, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 13 with value: 0.08404381787404418.\n",
      "[I 2025-08-17 19:42:02,328] Trial 16 finished with value: 0.07632415876723826 and parameters: {'batch_size': 32, 'lr': 4.7393410043092185e-05, 'optimizer': 'Adam', 'epochs': 89, 'n_layers': 4, 'hidden_dim': 500, 'dropout_rate': 0.15765416260162898, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 16 with value: 0.07632415876723826.\n",
      "[I 2025-08-17 19:42:23,731] Trial 17 finished with value: 0.08973288778215646 and parameters: {'batch_size': 32, 'lr': 0.0001804192797864964, 'optimizer': 'Adam', 'epochs': 90, 'n_layers': 5, 'hidden_dim': 496, 'dropout_rate': 0.14462228270557487, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 16 with value: 0.07632415876723826.\n",
      "[I 2025-08-17 19:42:41,854] Trial 18 finished with value: 0.11569072622805834 and parameters: {'batch_size': 32, 'lr': 4.8284771008137665e-05, 'optimizer': 'Adam', 'epochs': 68, 'n_layers': 4, 'hidden_dim': 215, 'dropout_rate': 0.15826161032111202, 'activation': 'leaky_relu', 'use_batchnorm': True}. Best is trial 16 with value: 0.07632415876723826.\n",
      "[I 2025-08-17 19:42:47,637] Trial 19 finished with value: 0.06328740585595369 and parameters: {'batch_size': 128, 'lr': 0.00015471073711434153, 'optimizer': 'Adam', 'epochs': 86, 'n_layers': 3, 'hidden_dim': 350, 'dropout_rate': 0.005534066038874935, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 19 with value: 0.06328740585595369.\n",
      "[I 2025-08-17 19:42:53,461] Trial 20 finished with value: 0.07836276795715094 and parameters: {'batch_size': 128, 'lr': 0.00013336372833393052, 'optimizer': 'Adam', 'epochs': 86, 'n_layers': 3, 'hidden_dim': 530, 'dropout_rate': 0.0056465429422754565, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 19 with value: 0.06328740585595369.\n",
      "[I 2025-08-17 19:42:59,564] Trial 21 finished with value: 0.060305388644337654 and parameters: {'batch_size': 128, 'lr': 0.00017354962311365348, 'optimizer': 'Adam', 'epochs': 87, 'n_layers': 3, 'hidden_dim': 524, 'dropout_rate': 0.011821131613319363, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:03,511] Trial 22 finished with value: 0.08086943440139294 and parameters: {'batch_size': 128, 'lr': 0.0003445893754105585, 'optimizer': 'Adam', 'epochs': 68, 'n_layers': 3, 'hidden_dim': 563, 'dropout_rate': 0.007417614308966839, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:09,605] Trial 23 finished with value: 0.08021531701087951 and parameters: {'batch_size': 128, 'lr': 0.00014284753078265834, 'optimizer': 'Adam', 'epochs': 85, 'n_layers': 3, 'hidden_dim': 449, 'dropout_rate': 0.09596710080760949, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:15,904] Trial 24 finished with value: 0.07039096597582102 and parameters: {'batch_size': 128, 'lr': 0.0004454869660263466, 'optimizer': 'Adam', 'epochs': 92, 'n_layers': 2, 'hidden_dim': 177, 'dropout_rate': 0.03664072317938552, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:22,159] Trial 25 finished with value: 0.0769853951409459 and parameters: {'batch_size': 128, 'lr': 0.0009207274344409119, 'optimizer': 'Adam', 'epochs': 93, 'n_layers': 2, 'hidden_dim': 143, 'dropout_rate': 0.003994341232072583, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:26,853] Trial 26 finished with value: 0.09136505611240864 and parameters: {'batch_size': 128, 'lr': 0.0005259126950413384, 'optimizer': 'Adam', 'epochs': 74, 'n_layers': 2, 'hidden_dim': 166, 'dropout_rate': 0.05151334722248049, 'activation': 'leaky_relu', 'use_batchnorm': True}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:31,682] Trial 27 finished with value: 0.07709462456405163 and parameters: {'batch_size': 128, 'lr': 0.0004144617336299259, 'optimizer': 'Adam', 'epochs': 83, 'n_layers': 2, 'hidden_dim': 333, 'dropout_rate': 0.11541253839189862, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:36,016] Trial 28 finished with value: 0.0721278440207243 and parameters: {'batch_size': 128, 'lr': 0.0002182554158602299, 'optimizer': 'Adam', 'epochs': 62, 'n_layers': 3, 'hidden_dim': 377, 'dropout_rate': 0.07375825563343805, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:43,515] Trial 29 finished with value: 0.15233753435313702 and parameters: {'batch_size': 64, 'lr': 0.0002342719484981598, 'optimizer': 'SGD', 'epochs': 79, 'n_layers': 2, 'hidden_dim': 280, 'dropout_rate': 0.03921860272283494, 'activation': 'leaky_relu', 'use_batchnorm': True}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:47,177] Trial 30 finished with value: 0.08018585927784443 and parameters: {'batch_size': 128, 'lr': 0.0003269173454838458, 'optimizer': 'Adam', 'epochs': 71, 'n_layers': 2, 'hidden_dim': 446, 'dropout_rate': 0.04547190404284843, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:50,520] Trial 31 finished with value: 0.08069217707961798 and parameters: {'batch_size': 128, 'lr': 0.000232898339846403, 'optimizer': 'Adam', 'epochs': 61, 'n_layers': 3, 'hidden_dim': 389, 'dropout_rate': 0.08763954275288714, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:53,839] Trial 32 finished with value: 0.07548833582550288 and parameters: {'batch_size': 128, 'lr': 0.000167584063810229, 'optimizer': 'Adam', 'epochs': 53, 'n_layers': 3, 'hidden_dim': 192, 'dropout_rate': 0.06076208098952454, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:43:58,171] Trial 33 finished with value: 0.10244884863495826 and parameters: {'batch_size': 128, 'lr': 0.00020541621315878146, 'optimizer': 'Adam', 'epochs': 63, 'n_layers': 3, 'hidden_dim': 32, 'dropout_rate': 0.02422253554181264, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:04,393] Trial 34 finished with value: 0.09383518956601619 and parameters: {'batch_size': 128, 'lr': 0.00011818616291959142, 'optimizer': 'Adam', 'epochs': 92, 'n_layers': 3, 'hidden_dim': 391, 'dropout_rate': 0.07882820052260825, 'activation': 'relu', 'use_batchnorm': True}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:10,827] Trial 35 finished with value: 0.5567766278982162 and parameters: {'batch_size': 64, 'lr': 0.00043082565623447954, 'optimizer': 'SGD', 'epochs': 57, 'n_layers': 3, 'hidden_dim': 601, 'dropout_rate': 0.026288768166155444, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:15,667] Trial 36 finished with value: 0.11716216877102852 and parameters: {'batch_size': 128, 'lr': 0.0002870783098218288, 'optimizer': 'Adam', 'epochs': 79, 'n_layers': 2, 'hidden_dim': 431, 'dropout_rate': 0.46562741046189215, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:20,071] Trial 37 finished with value: 0.33898316919803617 and parameters: {'batch_size': 128, 'lr': 8.90244273590568e-05, 'optimizer': 'SGD', 'epochs': 66, 'n_layers': 3, 'hidden_dim': 310, 'dropout_rate': 0.07439072087491594, 'activation': 'relu', 'use_batchnorm': True}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:24,035] Trial 38 finished with value: 0.07378629334270954 and parameters: {'batch_size': 128, 'lr': 0.0006469798176281595, 'optimizer': 'Adam', 'epochs': 73, 'n_layers': 2, 'hidden_dim': 634, 'dropout_rate': 0.11763333853301221, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:29,631] Trial 39 finished with value: 0.1238190233707428 and parameters: {'batch_size': 64, 'lr': 0.00028715933109920463, 'optimizer': 'Adam', 'epochs': 54, 'n_layers': 3, 'hidden_dim': 371, 'dropout_rate': 0.2753289311036766, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:33,640] Trial 40 finished with value: 0.963917362689972 and parameters: {'batch_size': 128, 'lr': 6.780590798398432e-05, 'optimizer': 'SGD', 'epochs': 79, 'n_layers': 3, 'hidden_dim': 788, 'dropout_rate': 0.062212684294328, 'activation': 'relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:37,264] Trial 41 finished with value: 0.07020269818603993 and parameters: {'batch_size': 128, 'lr': 0.0007440250369854777, 'optimizer': 'Adam', 'epochs': 72, 'n_layers': 2, 'hidden_dim': 697, 'dropout_rate': 0.10322321577092017, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:41,381] Trial 42 finished with value: 0.07006000149995088 and parameters: {'batch_size': 128, 'lr': 0.000996870786887789, 'optimizer': 'Adam', 'epochs': 85, 'n_layers': 2, 'hidden_dim': 761, 'dropout_rate': 0.03336136618537518, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:45,399] Trial 43 finished with value: 0.09262527376413346 and parameters: {'batch_size': 128, 'lr': 0.0009776534181050334, 'optimizer': 'Adam', 'epochs': 86, 'n_layers': 2, 'hidden_dim': 726, 'dropout_rate': 0.028559147847475163, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:44:49,972] Trial 44 finished with value: 0.07238689605146646 and parameters: {'batch_size': 128, 'lr': 0.0007953942676363712, 'optimizer': 'Adam', 'epochs': 76, 'n_layers': 2, 'hidden_dim': 835, 'dropout_rate': 0.001239360568843384, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:45:09,474] Trial 45 finished with value: 0.10931545407511294 and parameters: {'batch_size': 16, 'lr': 0.0005444840353623535, 'optimizer': 'Adam', 'epochs': 83, 'n_layers': 2, 'hidden_dim': 737, 'dropout_rate': 0.1892654974633203, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:45:13,532] Trial 46 finished with value: 0.08705165311694145 and parameters: {'batch_size': 128, 'lr': 0.0007698665733570318, 'optimizer': 'Adam', 'epochs': 94, 'n_layers': 2, 'hidden_dim': 659, 'dropout_rate': 0.10135547363364357, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:45:17,904] Trial 47 finished with value: 0.08230158351361752 and parameters: {'batch_size': 128, 'lr': 0.00043980312345524934, 'optimizer': 'Adam', 'epochs': 98, 'n_layers': 2, 'hidden_dim': 789, 'dropout_rate': 0.02549256743115899, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:45:37,551] Trial 48 finished with value: 0.14694081007037313 and parameters: {'batch_size': 16, 'lr': 0.0006694548011649052, 'optimizer': 'SGD', 'epochs': 88, 'n_layers': 2, 'hidden_dim': 860, 'dropout_rate': 0.04940718725631005, 'activation': 'leaky_relu', 'use_batchnorm': True}. Best is trial 21 with value: 0.060305388644337654.\n",
      "[I 2025-08-17 19:45:41,729] Trial 49 finished with value: 0.07525806166231633 and parameters: {'batch_size': 128, 'lr': 0.0004920581872322149, 'optimizer': 'Adam', 'epochs': 82, 'n_layers': 2, 'hidden_dim': 908, 'dropout_rate': 0.1319586449812829, 'activation': 'leaky_relu', 'use_batchnorm': False}. Best is trial 21 with value: 0.060305388644337654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial : {'batch_size': 128, 'lr': 0.00017354962311365348, 'optimizer': 'Adam', 'epochs': 87, 'n_layers': 3, 'hidden_dim': 524, 'dropout_rate': 0.011821131613319363, 'activation': 'relu', 'use_batchnorm': False}\n"
     ]
    }
   ],
   "source": [
    "# 実行\n",
    "print('Optuna最適化開始...')\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50) # 試行回数を増やす\n",
    "\n",
    "print('Best trial :', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af7920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 49.7124\n",
      "Fold MAE : 34.7088\n",
      "Fold R2  : 0.7641\n",
      "\n",
      "Fold RMSE : 43.7754\n",
      "Fold MAE : 28.2927\n",
      "Fold R2  : 0.8114\n",
      "\n",
      "Fold RMSE : 62.1350\n",
      "Fold MAE : 36.7677\n",
      "Fold R2  : 0.7271\n",
      "\n",
      "Fold RMSE : 42.8854\n",
      "Fold MAE : 32.9179\n",
      "Fold R2  : 0.8431\n",
      "\n",
      "Fold RMSE : 61.7221\n",
      "Fold MAE : 38.7026\n",
      "Fold R2  : 0.6279\n",
      "\n",
      "平均RMSE: 52.0461 ± 8.4045\n",
      "平均MAE: 34.2779 ± 3.5675\n",
      "平均R2: 0.7547 ± 0.0748\n"
     ]
    }
   ],
   "source": [
    "# optunaで最適化されたパラメータをセットし、予測\n",
    "\n",
    "# 評価指標格納用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # 分割\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_val = X.iloc[val_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_val = y.iloc[val_index]\n",
    "\n",
    "    # 標準化（情報漏洩防止）\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X_train = X_scaler.fit_transform(X_train)\n",
    "    autoscaled_X_val = X_scaler.transform(X_val)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    autoscaled_y_val = y_scaler.transform(y_val.values.reshape(-1, 1))\n",
    "\n",
    "    # DataLoader\n",
    "    train_ds = RegressionDataset(autoscaled_X_train, autoscaled_y_train)\n",
    "    val_ds = RegressionDataset(autoscaled_X_val, autoscaled_y_val)\n",
    "    train_dl = DataLoader(train_ds, batch_size=study.best_trial.params['batch_size'], shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=study.best_trial.params['batch_size'], shuffle=False)\n",
    "\n",
    "    # モデル構築\n",
    "    model_nn_op = define_model(study.best_trial, input_dim=autoscaled_X_train.shape[1]).to(device)\n",
    "    optimizer_name = study.best_trial.params['optimizer']\n",
    "    lr = study.best_trial.params['lr']\n",
    "    optimizer = torch.optim.Adam(model_nn_op.parameters(), lr=lr) if optimizer_name == \"Adam\" else torch.optim.SGD(model_nn_op.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 学習ループ\n",
    "    epochs = study.best_trial.params['epochs']  # Optuna で最適化されたエポック数を使う\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model_nn_op, train_dl, optimizer, criterion, device)\n",
    "\n",
    "    # 推論と逆変換\n",
    "    model_nn_op.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_dl:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_std = model_nn_op(X_batch).cpu().numpy()\n",
    "            preds.append(y_pred_std)\n",
    "\n",
    "    y_pred = y_scaler.inverse_transform(np.vstack(preds))\n",
    "    y_true = y_scaler.inverse_transform(autoscaled_y_val)\n",
    "\n",
    "    # 評価指標\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2  : {r2:.4f}\\n')\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# 結果出力\n",
    "print(f'平均RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}')\n",
    "print(f'平均MAE: {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}')\n",
    "print(f'平均R2: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405044a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてのデータを学習させて、保存\n",
    "# 全データで標準化\n",
    "X_scaler_final = StandardScaler()\n",
    "y_scaler_final = StandardScaler()\n",
    "autoscaled_X = X_scaler_final.fit_transform(X)\n",
    "autoscaled_y = y_scaler_final.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Dataset, DataLoader\n",
    "final_ds = RegressionDataset(autoscaled_X, autoscaled_y)\n",
    "final_dl = DataLoader(final_ds, batch_size=study.best_trial.params['batch_size'], shuffle=True)\n",
    "\n",
    "# モデル定義\n",
    "final_model = define_model(study.best_trial, input_dim=autoscaled_X.shape[1]).to(device)\n",
    "optimizer_name = study.best_trial.params['optimizer']\n",
    "lr = study.best_trial.params['lr']\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=lr) if optimizer_name == \"Adam\" else torch.optim.SGD(final_model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "epochs = study.best_trial.params['epochs']\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(epochs):\n",
    "    train(final_model, final_dl, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3aa1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nn/y_scaler.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存先ディレクトリを作成（なければ）\n",
    "os.makedirs('models/nn', exist_ok=True)\n",
    "\n",
    "# PyTorchモデルの保存（state_dict）、モデルの重み\n",
    "torch.save(final_model.state_dict(), 'models/nn/final_model.pth')\n",
    "\n",
    "# Optunaのbest_trial(ハイパラ)\n",
    "joblib.dump(study.best_trial.params, 'models/nn/hparams.pkl')\n",
    "\n",
    "# 特徴量名（列順の再現用)\n",
    "joblib.dump(list(X.columns), 'models/nn/feature_names.pkl')\n",
    "\n",
    "# スケーラーの保存（joblib）\n",
    "joblib.dump(X_scaler_final, 'models/nn/X_scaler.pkl')\n",
    "joblib.dump(y_scaler_final, 'models/nn/y_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol-regression-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
