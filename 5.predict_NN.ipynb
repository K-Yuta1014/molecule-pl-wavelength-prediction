{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f56bc6e",
   "metadata": {},
   "source": [
    "# 新規材料の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcce2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mol-regression-env/lib/python3.9/site-packages/xgboost/compat.py:105: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', font_scale=1.2)  # seabornスタイル適用\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e46c7",
   "metadata": {},
   "source": [
    "## データ読み込み＆前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec76cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233, 3), (233, 217), (233, 2048), (233, 1158), (233, 1826))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ読み込み、学習データ＋未知のデータ\n",
    "data = pd.read_csv('material_data.csv', index_col=0)\n",
    "# rdkit\n",
    "des_rdkit = pd.read_csv('descriptor_rdkit.csv', index_col=0)\n",
    "# FP\n",
    "fingerprint_df = pd.read_csv('morganFP.csv', index_col=0)\n",
    "# mordred, 2次元\n",
    "des_mordred_2d = pd.read_csv('descriptor_mordred_2d.csv', index_col=0)\n",
    "# mordred, 3次元\n",
    "des_mordred_3d = pd.read_csv('descriptor_mordred_3d.csv', index_col=0)\n",
    "\n",
    "data.shape, des_rdkit.shape, fingerprint_df.shape, des_mordred_2d.shape, des_mordred_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f1edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 152) (5, 151)\n"
     ]
    }
   ],
   "source": [
    "# 結合\n",
    "dataset = pd.concat([data.reset_index(), des_rdkit.reset_index(drop=True)], axis=1)\n",
    "\n",
    "dataset.index = dataset['Material']\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "\n",
    "# TypeとSMILESも消す\n",
    "dataset = dataset.drop(['SMILES', 'Type'], axis=1)\n",
    "\n",
    "# 学習用と予測用に分ける\n",
    "dataset_train = dataset.dropna(subset='PL')\n",
    "dataset_test = dataset[dataset['PL'].isnull()]\n",
    "\n",
    "# 予測データのPLは空なので消す\n",
    "dataset_test = dataset_test.drop('PL', axis=1)\n",
    "\n",
    "# infをNaNに置き換え\n",
    "dataset_train = dataset_train.replace(np.inf, np.nan).fillna(np.nan)\n",
    "dataset_train = dataset_train.drop(dataset_train.columns[dataset_train.isnull().any()], axis=1)\n",
    "\n",
    "dataset_test = dataset_test.replace(np.inf, np.nan).fillna(np.nan)\n",
    "dataset_test = dataset_test.drop(dataset_test.columns[dataset_test.isnull().any()], axis=1)\n",
    "\n",
    "# 学習データのstdが0の列を特定\n",
    "zero_std_cols = dataset_train.columns[dataset_train.std() == 0]\n",
    "\n",
    "# 学習・未知データから同じ列を削除\n",
    "dataset_train = dataset_train.drop(columns=zero_std_cols)\n",
    "dataset_test = dataset_test.drop(columns=zero_std_cols, errors='ignore')  # 念のため\n",
    "\n",
    "print(dataset_train.shape, dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199f65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な特徴量共通セット\n",
    "X_train_all = dataset_train.drop(columns='PL')\n",
    "y_train_all = dataset_train['PL']\n",
    "X_test = dataset_test  # PLなし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35092a",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e79ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b46dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット定義\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "# 学習loop\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 評価\n",
    "def evaluate(model, dataloader, device, y_scaler):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.cpu().numpy()\n",
    "            pred = model(X_batch).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            trues.append(y_batch)\n",
    "\n",
    "    y_pred_std = np.vstack(preds)\n",
    "    y_true_std = np.vstack(trues)\n",
    "\n",
    "    # 逆標準化\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_std)\n",
    "    y_true = y_scaler.inverse_transform(y_true_std)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af209451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna設定\n",
    "def define_model(trial, input_dim):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"])\n",
    "\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        layers.append(nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU() if activation == \"relu\" else nn.LeakyReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "    layers.append(nn.Linear(hidden_dim, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータ提案\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    val_losses = []\n",
    "\n",
    "    # 分割前に標準化してしまう\n",
    "    X_scaler = StandardScaler()\n",
    "    autoscaled_X = X_scaler.fit_transform(X_train_all)\n",
    "    y_scaler = StandardScaler()\n",
    "    autoscaled_y = y_scaler.fit_transform(y_train_all.values.reshape(-1, 1))\n",
    "\n",
    "    for train_idx, val_idx in kf.split(autoscaled_X):\n",
    "        # スライス\n",
    "        X_train, X_val = autoscaled_X[train_idx], autoscaled_X[val_idx]\n",
    "        y_train, y_val = autoscaled_y[train_idx], autoscaled_y[val_idx]\n",
    "\n",
    "        # Dataset, DataLoader\n",
    "        train_ds = RegressionDataset(X_train, y_train)\n",
    "        val_ds = RegressionDataset(X_val, y_val)\n",
    "\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # モデル定義\n",
    "        model = define_model(trial, X_train.shape[1]).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr) if optimizer_name == \"Adam\" else torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # 学習ループ\n",
    "        for epoch in range(50):\n",
    "            train(model, train_dl, optimizer, criterion, device)\n",
    "\n",
    "        # 評価\n",
    "        val_loss = evaluate(model, val_dl, device, y_scaler)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return np.mean(val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0677d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 20:37:24,114] A new study created in memory with name: no-name-a9857564-e4aa-4cfa-b994-381d2fdc60fe\n",
      "[I 2025-07-03 20:37:35,952] Trial 0 finished with value: 80.50936827247504 and parameters: {'batch_size': 16, 'lr': 0.00926298504585722, 'optimizer': 'Adam', 'n_layers': 3, 'hidden_dim': 386, 'dropout_rate': 0.2938193630456313, 'activation': 'leaky_relu'}. Best is trial 0 with value: 80.50936827247504.\n",
      "[I 2025-07-03 20:37:43,957] Trial 1 finished with value: 98.63079913644268 and parameters: {'batch_size': 32, 'lr': 0.0029308610582944594, 'optimizer': 'SGD', 'n_layers': 5, 'hidden_dim': 416, 'dropout_rate': 0.40553641043943056, 'activation': 'relu'}. Best is trial 0 with value: 80.50936827247504.\n",
      "[I 2025-07-03 20:37:48,814] Trial 2 finished with value: 79.53407312622943 and parameters: {'batch_size': 32, 'lr': 0.0016547827932387412, 'optimizer': 'SGD', 'n_layers': 3, 'hidden_dim': 213, 'dropout_rate': 0.10483916209291633, 'activation': 'leaky_relu'}. Best is trial 2 with value: 79.53407312622943.\n",
      "[I 2025-07-03 20:37:51,040] Trial 3 finished with value: 53.58813376344729 and parameters: {'batch_size': 64, 'lr': 0.0032049205937973524, 'optimizer': 'SGD', 'n_layers': 1, 'hidden_dim': 392, 'dropout_rate': 0.4348682051419288, 'activation': 'relu'}. Best is trial 3 with value: 53.58813376344729.\n",
      "[I 2025-07-03 20:38:03,240] Trial 4 finished with value: 98.77754027224822 and parameters: {'batch_size': 16, 'lr': 0.001547537101407616, 'optimizer': 'SGD', 'n_layers': 5, 'hidden_dim': 393, 'dropout_rate': 0.3784826373397305, 'activation': 'relu'}. Best is trial 3 with value: 53.58813376344729.\n",
      "[I 2025-07-03 20:38:05,643] Trial 5 finished with value: 46.21140307015665 and parameters: {'batch_size': 64, 'lr': 0.001981207695067718, 'optimizer': 'Adam', 'n_layers': 1, 'hidden_dim': 436, 'dropout_rate': 0.13967576009011845, 'activation': 'relu'}. Best is trial 5 with value: 46.21140307015665.\n",
      "[I 2025-07-03 20:38:16,310] Trial 6 finished with value: 46.28473994697517 and parameters: {'batch_size': 32, 'lr': 0.006401550754107242, 'optimizer': 'Adam', 'n_layers': 4, 'hidden_dim': 436, 'dropout_rate': 0.26307613919694184, 'activation': 'relu'}. Best is trial 5 with value: 46.21140307015665.\n",
      "[I 2025-07-03 20:38:22,883] Trial 7 finished with value: 72.6952487691343 and parameters: {'batch_size': 32, 'lr': 0.005492840724753778, 'optimizer': 'SGD', 'n_layers': 4, 'hidden_dim': 128, 'dropout_rate': 0.2573795262993076, 'activation': 'leaky_relu'}. Best is trial 5 with value: 46.21140307015665.\n",
      "[I 2025-07-03 20:38:27,304] Trial 8 finished with value: 43.80313911075521 and parameters: {'batch_size': 32, 'lr': 0.0007828073722491185, 'optimizer': 'Adam', 'n_layers': 2, 'hidden_dim': 123, 'dropout_rate': 0.346099179682175, 'activation': 'relu'}. Best is trial 8 with value: 43.80313911075521.\n",
      "[I 2025-07-03 20:38:42,494] Trial 9 finished with value: 42.713514914661346 and parameters: {'batch_size': 16, 'lr': 0.0011851505738656768, 'optimizer': 'Adam', 'n_layers': 5, 'hidden_dim': 437, 'dropout_rate': 0.10246354938881719, 'activation': 'relu'}. Best is trial 9 with value: 42.713514914661346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial : {'batch_size': 16, 'lr': 0.0011851505738656768, 'optimizer': 'Adam', 'n_layers': 5, 'hidden_dim': 437, 'dropout_rate': 0.10246354938881719, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# 実行\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best trial :', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b827d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE : 42.3110\n",
      "Fold MAE : 30.3051\n",
      "Fold R2  : 0.8063\n",
      "\n",
      "Fold RMSE : 56.6759\n",
      "Fold MAE : 40.0587\n",
      "Fold R2  : 0.7389\n",
      "\n",
      "Fold RMSE : 45.6701\n",
      "Fold MAE : 32.2292\n",
      "Fold R2  : 0.7978\n",
      "\n",
      "Fold RMSE : 34.1775\n",
      "Fold MAE : 25.9352\n",
      "Fold R2  : 0.8527\n",
      "\n",
      "Fold RMSE : 38.6853\n",
      "Fold MAE : 28.7894\n",
      "Fold R2  : 0.8158\n",
      "\n",
      "\n",
      "平均RMSE : 43.5039\n",
      "平均MAE  : 31.4635\n",
      "平均R2   : 0.8023\n"
     ]
    }
   ],
   "source": [
    "# 汎化性能チェック\n",
    "# 評価指標格納用\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# 分割前に標準化してしまう\n",
    "X_scaler = StandardScaler()\n",
    "autoscaled_X = X_scaler.fit_transform(X_train_all)\n",
    "y_scaler = StandardScaler()\n",
    "autoscaled_y = y_scaler.fit_transform(y_train_all.values.reshape(-1, 1))\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for train_index, val_index in kf.split(autoscaled_X):\n",
    "    # データ分割\n",
    "    X_train, X_val = autoscaled_X[train_index], autoscaled_X[val_index]\n",
    "    y_train, y_val = autoscaled_y[train_index], autoscaled_y[val_index]\n",
    "\n",
    "    # Dataset/DataLoader\n",
    "    train_ds = RegressionDataset(X_train, y_train)\n",
    "    val_ds = RegressionDataset(X_val, y_val)\n",
    "    train_dl = DataLoader(train_ds, batch_size=study.best_trial.params['batch_size'], shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=study.best_trial.params['batch_size'], shuffle=False)\n",
    "\n",
    "    # モデルと最適化\n",
    "    model_nn_op = define_model(study.best_trial, input_dim=X_train.shape[1]).to(device)\n",
    "    if study.best_trial.params['optimizer'] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model_nn_op.parameters(), lr=study.best_trial.params['lr'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model_nn_op.parameters(), lr=study.best_trial.params['lr'])\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # 学習\n",
    "    for epoch in range(30):  # 固定でOKなら30\n",
    "        model_nn_op.train()\n",
    "        for X_batch, y_batch in train_dl:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model_nn_op(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 標準化された予測 → 逆変換\n",
    "    model_nn_op.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dl:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.cpu().numpy()\n",
    "            y_pred_std = model_nn_op(X_batch).cpu().numpy()\n",
    "            preds.append(y_pred_std)\n",
    "            trues.append(y_batch)\n",
    "\n",
    "    y_pred_std = np.vstack(preds)\n",
    "    y_true_std = np.vstack(trues)\n",
    "\n",
    "    # 逆標準化\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_std)\n",
    "    y_true = y_scaler.inverse_transform(y_true_std)\n",
    "\n",
    "    # 評価（同じスケールで比較）\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Fold RMSE : {rmse:.4f}')\n",
    "    print(f'Fold MAE : {mae:.4f}')\n",
    "    print(f'Fold R2  : {r2:.4f}\\n')\n",
    "\n",
    "    # 結果格納\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# 平均結果出力\n",
    "print(f'\\n平均RMSE : {np.mean(rmse_scores):.4f}')\n",
    "print(f'平均MAE  : {np.mean(mae_scores):.4f}')\n",
    "print(f'平均R2   : {np.mean(r2_scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f42ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol-regression-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
